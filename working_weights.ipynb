{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "working_weights.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMfWkq4Kr/MxP9xTrsV5ayz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/gan_segmentation_FE/blob/main/working_weights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkihMbsoz1hZ",
        "outputId": "f168e0f3-4256-49ae-899e-09718f8d5f25"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG2pnjJY0ORv"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/gdrive/My Drive/segmentation/Training_Batch1.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhMRVutR0OOe"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "for i in range(5,28):\n",
        "    os.remove( '/content/media/nas/01_Datasets/CT/LITS/Training Batch 1/segmentation-'+str(i)+'.nii')\n",
        "    os.remove( '/content/media/nas/01_Datasets/CT/LITS/Training Batch 1/volume-'+str(i)+'.nii')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJMLGdoI0Ybc",
        "outputId": "814c356b-8867-47be-bc42-e7de455ab25c"
      },
      "source": [
        "pip install medpy"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting medpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/70/c1fd5dd60242eee81774696ea7ba4caafac2bad8f028bba94b1af83777d7/MedPy-0.4.0.tar.gz (151kB)\n",
            "\r\u001b[K     |██▏                             | 10kB 12.0MB/s eta 0:00:01\r\u001b[K     |████▎                           | 20kB 16.9MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 30kB 19.5MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 40kB 16.1MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 51kB 17.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 61kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 71kB 12.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 81kB 12.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 92kB 13.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 102kB 14.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 112kB 14.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 122kB 14.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 133kB 14.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 143kB 14.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 153kB 14.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.19.5)\n",
            "Collecting SimpleITK>=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/6b/85df5eb3a8059b23a53a9f224476e75473f9bcc0a8583ed1a9c34619f372/SimpleITK-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (47.4MB)\n",
            "\u001b[K     |████████████████████████████████| 47.4MB 60kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: medpy\n",
            "  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for medpy: filename=MedPy-0.4.0-cp37-cp37m-linux_x86_64.whl size=754486 sha256=743636917da64ce5b02ea7c3bad86c5865452527b065ec52521623dc438221bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/c9/9c/2c6281c7a72b9fb1570862a4f028af7ce38405008354fbf870\n",
            "Successfully built medpy\n",
            "Installing collected packages: SimpleITK, medpy\n",
            "Successfully installed SimpleITK-2.0.2 medpy-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRzJyZ270YYk",
        "outputId": "82499656-5c35-4a10-ce9c-ecc51ce5ad38"
      },
      "source": [
        "from medpy.io import load, save\n",
        "import os\n",
        "import os.path\n",
        "import gc\n",
        "from scipy.ndimage import zoom\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "try:\n",
        "  os.mkdir('data')\n",
        "except:\n",
        "  pass\n",
        "for file in tqdm(range(5)):\n",
        "        shape=4/2\n",
        "        img, img_header = load('/content/media/nas/01_Datasets/CT/LITS/Training Batch 1/volume-'+str(file)+'.nii')\n",
        "        seg, img_header = load('/content/media/nas/01_Datasets/CT/LITS/Training Batch 1/segmentation-'+str(file)+'.nii')\n",
        "        arr=np.where(seg==2)[-1]\n",
        "        mn=(arr.min()+arr.max())/2\n",
        "        \n",
        "        \n",
        "        if mn-shape<0:\n",
        "          start=0\n",
        "          end=shape*2\n",
        "        elif mn+shape>img.shape[-1]:\n",
        "          end=img.shape[-1]\n",
        "          start=end-shape*2\n",
        "        else:\n",
        "          start=int(max(0,(mn-shape)))\n",
        "          end=int(min(img.shape[-1],int(mn+shape)))\n",
        "        \n",
        "        \n",
        "        img=img[:,:,start:end]\n",
        "        img[img < -200] = -200\n",
        "        img[img > 250] = 250\n",
        "        img+=112\n",
        "        img/=117\n",
        "        img = np.array(img, dtype='float32')\n",
        "        # img = zoom(img, (0.125, 0.125, 1))\n",
        "        # print (\"Saving image \"+str(file))\n",
        "        # np.save( \"/content/data/volume-\" + str(file) ,zoom(img, (0.125, 0.125, 1)))\n",
        "        # print(img.shape)\n",
        "        # del([img])\n",
        "        # gc.collect()\n",
        "        seg=seg.astype('float64')\n",
        "        seg+=0.1645\n",
        "        seg/=0.023138\n",
        "        seg = np.array(seg, dtype='float32')\n",
        "        seg=seg[:,:,start:end]\n",
        "        # print (\"Saving image \"+file)\n",
        "        # seg=zoom(seg, (0.125, 0.125, 1))\n",
        "        total=np.concatenate([img,seg],-1)\n",
        "        print(total.shape)\n",
        "        np.save( \"/content/data/total-\" + str(file),total)\n",
        "        del([seg,img,total])\n",
        "        gc.collect()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|██        | 1/5 [00:00<00:02,  1.52it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(512, 512, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 40%|████      | 2/5 [00:01<00:02,  1.34it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(512, 512, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 60%|██████    | 3/5 [00:06<00:03,  1.89s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(512, 512, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 80%|████████  | 4/5 [00:18<00:04,  4.92s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(512, 512, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 5/5 [00:37<00:00,  7.56s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(512, 512, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM4ue4GQzBBd",
        "outputId": "a8fb0000-5567-47ed-e7b5-809de1bce5b2"
      },
      "source": [
        "%%writefile ATLAS_dataset.py\n",
        "import csv\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import os\n",
        "from torchvision import transforms\n",
        "from skimage.transform import resize\n",
        "import nibabel as nib\n",
        "from skimage import exposure\n",
        "\n",
        "class ATLASdataset(Dataset):\n",
        "    def __init__(self,augmentation=True):\n",
        "        list_path = []\n",
        "        for i in range(9):\n",
        "            root = '../ATLAS_R1.1/Site'+str(i+1)\n",
        "        \n",
        "            list_img = os.listdir(root)\n",
        "            for s in range(len(list_img)):\n",
        "                list_path.append(os.path.join(root,list_img[s]))\n",
        "\n",
        "        list_path.sort()\n",
        "        self.augmentation= augmentation\n",
        "        self.imglist = list_path\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.imglist)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = os.path.join(self.imglist[index],'t01')\n",
        "        tempimg = nib.load(os.path.join(path,'T1w_p.nii'))\n",
        "        B = np.flip(tempimg.get_data(),1)\n",
        "        sp_size = 64\n",
        "        img = resize(B, (sp_size,sp_size,sp_size), mode='constant')\n",
        "        img = 1.0*img\n",
        "        img = (img-np.min(img))/(np.max(img)-np.min(img))\n",
        "\n",
        "        if self.augmentation:\n",
        "            random_n = torch.rand(1)\n",
        "            if random_n[0] > 0.5:\n",
        "                img = np.flip(img,0)\n",
        "                \n",
        "        img = np.ascontiguousarray(img,dtype=np.float32)\n",
        "\n",
        "        imageout = torch.from_numpy(img).float().view(1,sp_size,sp_size,sp_size)\n",
        "        imageout = 2*imageout-1\n",
        "\n",
        "        return imageout "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting ATLAS_dataset.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOUBCCNDy5qU",
        "outputId": "9ec6b273-13c7-41ec-a512-510b5266f513"
      },
      "source": [
        "%%writefile BRATS_dataset.py\n",
        "import csv\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import os\n",
        "from skimage.transform import resize\n",
        "from nilearn import surface\n",
        "import nibabel as nib\n",
        "from skimage import exposure\n",
        "\n",
        "class BRATSdataset(Dataset):\n",
        "    def __init__(self, train=True, imgtype = 'flair', severity='HGG',is_flip=False,augmentation=True):\n",
        "        self.augmentation = augmentation\n",
        "        if train:\n",
        "            self.root = '../Training_brats/' + severity\n",
        "        else:\n",
        "            self.root = '../Validation_brats'\n",
        "        self.imgtype = imgtype\n",
        "        list_img = os.listdir(self.root)\n",
        "        list_img.sort()\n",
        "        self.imglist = list_img\n",
        "        self.is_flip = is_flip\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.imglist)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        path = os.path.join(self.root,self.imglist[index])\n",
        "        \n",
        "        img = nib.load(os.path.join(path,self.imglist[index]+'_'+self.imgtype+'.nii.gz'))\n",
        "        gt = nib.load(os.path.join(path,self.imglist[index])+'_'+'seg.nii.gz')\n",
        "\n",
        "        A = np.zeros((240,240,166))\n",
        "        G = np.zeros((240,240,166))\n",
        "        A[:,:,11:] = img.get_data()\n",
        "        G[:,:,11:] = gt.get_data()\n",
        "        x=[]\n",
        "        y=[]\n",
        "        z=[]\n",
        "        \n",
        "        for i in range(240):\n",
        "            if np.all(A[i,:,:] ==0):\n",
        "                x.append(i)\n",
        "            if np.all(A[:,i,:]==0):\n",
        "                y.append(i)\n",
        "            if i <155:\n",
        "                if np.all(A[:,:,i]==0):\n",
        "                    z.append(i)\n",
        "\n",
        "        xl,yl,zl = 0,0,0\n",
        "        xh,yh,zh = 240,240,155\n",
        "        for xn in x:\n",
        "            if xn < 120:\n",
        "                if xn> xl:\n",
        "                    xl = xn\n",
        "            else:\n",
        "                if xn<xh:\n",
        "                    xh = xn\n",
        "        for yn in y:\n",
        "            if yn < 120:\n",
        "                if yn> yl:\n",
        "                    yl = yn\n",
        "            else:\n",
        "                if yn<yh:\n",
        "                    yh = yn\n",
        "        for zn in z:\n",
        "            if zn < 77:\n",
        "                if zn> zl:\n",
        "                    zl = zn\n",
        "            else:\n",
        "                if zn<zh:\n",
        "                    zh = zn\n",
        "\n",
        "        B = A[xl-10:xh+10,yl-10:yh+10,zl-10:zh+10]\n",
        "        B = resize(B, (128, 128, 128), mode='constant')\n",
        "        \n",
        "        if self.is_flip:\n",
        "            B = np.swapaxes(B,1,2)\n",
        "            B = np.flip(B,1)\n",
        "            B =np.flip(B,2)\n",
        "        \n",
        "        sp_size = 64\n",
        "        img = resize(B, (sp_size,sp_size,sp_size), mode='constant')\n",
        "        if self.augmentation:\n",
        "            random_n = torch.rand(1)\n",
        "            random_i = 0.3*torch.rand(1)[0]+0.7\n",
        "            if random_n[0] > 0.5:\n",
        "                img = np.flip(img,0)\n",
        "\n",
        "        img = 1.0*img\n",
        "        img = exposure.rescale_intensity(img)\n",
        "        img = (img-np.min(img))/(np.max(img)-np.min(img))\n",
        "        img = 2*img-1\n",
        "\n",
        "        imageout = torch.from_numpy(img).float().view(1,sp_size,sp_size,sp_size)\n",
        "\n",
        "        return imageout"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting BRATS_dataset.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmUcIoPe95T6",
        "outputId": "e61a6c91-9274-4340-edff-1ca61e3709c3"
      },
      "source": [
        "pip install nilearn"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nilearn in /usr/local/lib/python3.7/dist-packages (0.7.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.0.1)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.7/dist-packages (from nilearn) (2.23.0)\n",
            "Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn>=0.19 in /usr/local/lib/python3.7/dist-packages (from nilearn) (0.22.2.post1)\n",
            "Requirement already satisfied: nibabel>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from nilearn) (3.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->nilearn) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->nilearn) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.18.0->nilearn) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0cF752Iywks"
      },
      "source": [
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import os\n",
        "from torchvision import transforms\n",
        "from skimage.transform import resize\n",
        "from nilearn import surface\n",
        "from medpy.io import *\n",
        "import glob\n",
        "class ADNIdataset(Dataset):\n",
        "\tdef __init__(self, augmentation=False):\n",
        "\t\tself.augmentation = augmentation\n",
        "\t\tself.name = []\n",
        "\t\tfor data in glob.glob('/content/data/total-*.npy'):\n",
        "\t\t\tself.name.append(data)\n",
        "\t\tself.name = np.asarray(self.name)\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.name)\n",
        "\n",
        "\tdef __getitem__(self, index):\n",
        "\t\tpath = self.name[index]\n",
        "\t\timg = np.load(path)\n",
        "\n",
        "\t\timg = np.flip(img,1)\n",
        "\t\timg = np.flip(img,2)\n",
        "\t\tsp_size = 64\n",
        "\t\timg = resize(img, (sp_size,sp_size,sp_size), mode='constant')\n",
        "\t\tif self.augmentation:\n",
        "\t\t\trandom_n = torch.rand(1)\n",
        "\t\t\trandom_i = 0.3*torch.rand(1)[0]+0.7\n",
        "\t\t\tif random_n[0] > 0.5:\n",
        "\t\t\t\timg = np.flip(img,0)\n",
        "                \n",
        "\t\t\timg = img*random_i.data.cpu().numpy()\n",
        "            \n",
        "\t\timageout = torch.from_numpy(img).float().view(1,sp_size,sp_size,sp_size)\n",
        "\t\timageout = imageout*2-1\n",
        "\n",
        "\t\treturn imageout"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhoIGhT-YzEW"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GB0-ZngUjaA"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, channel=512):\n",
        "        super(Discriminator, self).__init__()        \n",
        "        self.channel = channel\n",
        "        n_class = 1\n",
        "        \n",
        "        self.conv1 = nn.Conv3d(1, channel//8, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv3d(channel//8, channel//4, kernel_size=4, stride=2, padding=1)\n",
        "        self.bn2 = nn.BatchNorm3d(channel//4)\n",
        "        self.conv3 = nn.Conv3d(channel//4, channel//2, kernel_size=4, stride=2, padding=1)\n",
        "        self.bn3 = nn.BatchNorm3d(channel//2)\n",
        "        self.conv4 = nn.Conv3d(channel//2, channel, kernel_size=4, stride=2, padding=1)\n",
        "        self.bn4 = nn.BatchNorm3d(channel)\n",
        "        \n",
        "        self.conv5 = nn.Conv3d(channel, n_class, kernel_size=4, stride=2, padding=1)\n",
        "        \n",
        "    def forward(self, x, _return_activations=False):\n",
        "        h1 = F.leaky_relu(self.conv1(x), negative_slope=0.2)\n",
        "        h2 = F.leaky_relu(self.bn2(self.conv2(h1)), negative_slope=0.2)\n",
        "        h3 = F.leaky_relu(self.bn3(self.conv3(h2)), negative_slope=0.2)\n",
        "        h4 = F.leaky_relu(self.bn4(self.conv4(h3)), negative_slope=0.2)\n",
        "        h5 = self.conv5(h4)\n",
        "        output = h5\n",
        "\n",
        "        return output\n",
        "    \n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise:int=1000, channel:int=64):\n",
        "        super(Generator, self).__init__()\n",
        "        _c = channel\n",
        "        \n",
        "        self.noise = noise\n",
        "        self.fc = nn.Linear(1000,512*4*4*4)\n",
        "        self.bn1 = nn.BatchNorm3d(_c*8)\n",
        "        \n",
        "        self.tp_conv2 = nn.Conv3d(_c*8, _c*4, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm3d(_c*4)\n",
        "        \n",
        "        self.tp_conv3 = nn.Conv3d(_c*4, _c*2, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm3d(_c*2)\n",
        "        \n",
        "        self.tp_conv4 = nn.Conv3d(_c*2, _c, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn4 = nn.BatchNorm3d(_c)\n",
        "        \n",
        "        self.tp_conv5 = nn.Conv3d(_c, 1, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        \n",
        "    def forward(self, noise):\n",
        "        noise = noise.view(-1, 1000)\n",
        "        h = self.fc(noise)\n",
        "        h = h.view(-1,512,4,4,4)\n",
        "        h = F.relu(self.bn1(h))\n",
        "\n",
        "        h = F.upsample(h,scale_factor = 2)\n",
        "        h = self.tp_conv2(h)\n",
        "        h = F.relu(self.bn2(h))\n",
        "        \n",
        "        h = F.upsample(h,scale_factor = 2)\n",
        "        h = self.tp_conv3(h)\n",
        "        h = F.relu(self.bn3(h))\n",
        "\n",
        "        h = F.upsample(h,scale_factor = 2)\n",
        "        h = self.tp_conv4(h)\n",
        "        h = F.relu(self.bn4(h))\n",
        "\n",
        "        h = F.upsample(h,scale_factor = 2)\n",
        "        h = self.tp_conv5(h)\n",
        "\n",
        "        h = F.tanh(h)\n",
        "\n",
        "        return h"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viwzmKOwypBn",
        "outputId": "55f8094e-0d5a-44fd-b501-99fffb324c21"
      },
      "source": [
        "%pylab inline\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "from torch import autograd\n",
        "from torch.autograd import Variable\n",
        "import nibabel as nib\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import dataloader\n",
        "from nilearn import plotting\n",
        "from BRATS_dataset import *\n",
        "from ATLAS_dataset import *\n",
        "from Model_WGAN import *\n",
        "\n",
        "\n",
        "BATCH_SIZE=4\n",
        "max_epoch = 100\n",
        "lr = 0.0001\n",
        "gpu = True\n",
        "workers = 4\n",
        "\n",
        "LAMBDA= 10\n",
        "#setting latent variable sizes\n",
        "latent_dim = 1000\n",
        "\n",
        "\n",
        "trainset = ADNIdataset(augmentation=True)\n",
        "train_loader = torch.utils.data.DataLoader(trainset,batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True,num_workers=workers)\n",
        "if Use_BRATS:\n",
        "    #'flair' or 't2' or 't1ce'\n",
        "    trainset = BRATSdataset(imgtype='flair')\n",
        "    train_loader = torch.utils.data.DataLoader(trainset,batch_size = BATCH_SIZE, shuffle=True,\n",
        "                                               num_workers=workers)\n",
        "if Use_ATLAS:\n",
        "    trainset = ATLASdataset(augmentation=True)\n",
        "    train_loader = torch.utils.data.DataLoader(trainset,batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True,num_workers=workers)\n",
        "\n",
        "def inf_train_gen(data_loader):\n",
        "    while True:\n",
        "        for _,images in enumerate(data_loader):\n",
        "            yield images\n",
        "\n",
        "\n",
        "D = Discriminator().cuda()\n",
        "G=Generator()\n",
        "a=torch.load('/content/gdrive/MyDrive/segmentation/WGAN_G(1).pth',map_location='cuda:0')\n",
        "G.load_state_dict(a)\n",
        "\n",
        "g_optimizer = optim.Adam(G.parameters(), lr=0.0002)\n",
        "d_optimizer = optim.Adam(D.parameters(), lr=0.0002)\n",
        "\n",
        "\n",
        "def calc_gradient_penalty(netD, real_data, fake_data):    \n",
        "    alpha = torch.rand(real_data.size(0),1,1,1,1)\n",
        "    alpha = alpha.expand(real_data.size())\n",
        "    \n",
        "    alpha = alpha.cuda()\n",
        "\n",
        "    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
        "\n",
        "    interpolates = interpolates.cuda()\n",
        "    interpolates = Variable(interpolates, requires_grad=True)\n",
        "\n",
        "    disc_interpolates = netD(interpolates)\n",
        "\n",
        "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
        "                              grad_outputs=torch.ones(disc_interpolates.size()).cuda(),\n",
        "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n",
        "    return gradient_penalty\n",
        "\n",
        "\n",
        "real_y = Variable(torch.ones((BATCH_SIZE, 1)).cuda())\n",
        "fake_y = Variable(torch.zeros((BATCH_SIZE, 1)).cuda())\n",
        "loss_f = nn.BCELoss()\n",
        "\n",
        "d_real_losses = list()\n",
        "d_fake_losses = list()\n",
        "d_losses = list()\n",
        "g_losses = list()\n",
        "divergences = list()\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['plotting', 'save', 'shape', 'resize', 'Generator', 'load']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT-xdxCwBXU2",
        "outputId": "82125d28-3fb6-4d23-a418-6b5b0d2411af"
      },
      "source": [
        "from tqdm import tqdm\n",
        "TOTAL_ITER = 200000\n",
        "gen_load = inf_train_gen(train_loader)\n",
        "for iteration in tqdm(range(TOTAL_ITER)):\n",
        "    ###############################################\n",
        "    # Train D \n",
        "    ###############################################\n",
        "    for p in D.parameters():  \n",
        "        p.requires_grad = True \n",
        "\n",
        "    real_images = gen_load.__next__()\n",
        "    if real_images.shape[0]==1:\n",
        "      real_images = gen_load.__next__()\n",
        "      \n",
        "    D.zero_grad()\n",
        "    real_images = Variable(real_images).cuda()\n",
        "\n",
        "    _batch_size = real_images.size(0)\n",
        "\n",
        "\n",
        "    y_real_pred = D(real_images)\n",
        "\n",
        "    d_real_loss = y_real_pred.mean()\n",
        "    \n",
        "    noise = Variable(torch.randn((_batch_size, latent_dim, 1, 1, 1)),volatile=True).cuda()\n",
        "    fake_images = G(noise)\n",
        "    y_fake_pred = D(fake_images.detach())\n",
        "\n",
        "    d_fake_loss = y_fake_pred.mean()\n",
        "\n",
        "    gradient_penalty = calc_gradient_penalty(D,real_images.data, fake_images.data)\n",
        " \n",
        "    d_loss = - d_real_loss + d_fake_loss +gradient_penalty\n",
        "    d_loss.backward()\n",
        "    Wasserstein_D = d_real_loss - d_fake_loss\n",
        "\n",
        "    d_optimizer.step()\n",
        "\n",
        "    ###############################################\n",
        "    # Train G \n",
        "    ###############################################\n",
        "    for p in D.parameters():\n",
        "        p.requires_grad = False\n",
        "        \n",
        "    for iters in range(5):\n",
        "        G.zero_grad()\n",
        "        noise = Variable(torch.randn((_batch_size, latent_dim, 1, 1 ,1)).cuda())\n",
        "        fake_image =G(noise)\n",
        "        y_fake_g = D(fake_image)\n",
        "\n",
        "        g_loss = -y_fake_g.mean()\n",
        "\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "    # ###############################################\n",
        "    # # Visualization\n",
        "    # ###############################################\n",
        "    # if iteration%10 == 0:\n",
        "    #     d_real_losses.append(d_real_loss.data[0])\n",
        "    #     d_fake_losses.append(d_fake_loss.data[0])\n",
        "    #     d_losses.append(d_loss.data[0])\n",
        "    #     g_losses.append(g_loss.data.cpu().numpy())\n",
        "\n",
        "    #     print('[{}/{}]'.format(iteration,TOTAL_ITER),\n",
        "    #           'D: {:<8.3}'.format(d_loss.data[0].cpu().numpy()), \n",
        "    #           'D_real: {:<8.3}'.format(d_real_loss.data[0].cpu().numpy()),\n",
        "    #           'D_fake: {:<8.3}'.format(d_fake_loss.data[0].cpu().numpy()), \n",
        "    #           'G: {:<8.3}'.format(g_loss.data[0].cpu().numpy()))\n",
        "\n",
        "    #     featmask = np.squeeze((0.5*fake_image+0.5)[0].data.cpu().numpy())\n",
        "\n",
        "    #     featmask = nib.Nifti1Image(featmask,affine = np.eye(4))\n",
        "    #     plotting.plot_img(featmask,title=\"FAKE\")\n",
        "    #     plotting.show()\n",
        "        \n",
        "    if (iteration+1)%500 ==0:\n",
        "        torch.save(G.state_dict(),'./checkpoint/G_W_iter'+str(iteration+1)+'.pth')\n",
        "        torch.save(D.state_dict(),'./checkpoint/D_W_iter'+str(iteration+1)+'.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/200000 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1698: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "\n",
            "  0%|          | 1/200000 [00:04<275:01:42,  4.95s/it]\u001b[A\n",
            "  0%|          | 2/200000 [00:10<277:10:05,  4.99s/it]\u001b[A\n",
            "  0%|          | 3/200000 [00:15<278:01:47,  5.00s/it]\u001b[A\n",
            "  0%|          | 4/200000 [00:20<278:58:36,  5.02s/it]\u001b[A\n",
            "  0%|          | 5/200000 [00:25<279:28:50,  5.03s/it]\u001b[A\n",
            "  0%|          | 6/200000 [00:30<279:46:02,  5.04s/it]\u001b[A\n",
            "  0%|          | 7/200000 [00:35<279:25:30,  5.03s/it]\u001b[A\n",
            "  0%|          | 8/200000 [00:40<279:32:01,  5.03s/it]\u001b[A\n",
            "  0%|          | 9/200000 [00:45<279:40:05,  5.03s/it]\u001b[A\n",
            "  0%|          | 10/200000 [00:50<278:50:48,  5.02s/it]\u001b[A\n",
            "  0%|          | 11/200000 [00:55<278:34:55,  5.01s/it]\u001b[A\n",
            "  0%|          | 12/200000 [01:00<278:54:34,  5.02s/it]\u001b[A\n",
            "  0%|          | 13/200000 [01:05<278:51:11,  5.02s/it]\u001b[A\n",
            "  0%|          | 14/200000 [01:10<279:01:56,  5.02s/it]\u001b[A\n",
            "  0%|          | 15/200000 [01:15<278:54:25,  5.02s/it]\u001b[A\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUeEq0TeDzyy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r21iMguKErKY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jviNRn6BErH0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nImhagtGErEs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjc8P1M5ErCM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1AgohhiEq_k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcAB97LoEq9H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}