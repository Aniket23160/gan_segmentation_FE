{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gan_segmentation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNz+OEoZ7sal8EvtQlLyBOT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/gan_segmentation_FE/blob/main/gan_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB9IbZ_eJD7p",
        "outputId": "ea9ed043-bb38-4a1b-e7bb-48b66069651e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOaLqvOCAbvx",
        "outputId": "a3acece5-0b8e-4184-c823-7abdb5c9bfa0"
      },
      "source": [
        "%%writefile util.py\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import glob\n",
        "def string_tensor_from_idlist_and_path(type, name = None):\n",
        "  file_names = glob.glob('/content/gdrive/MyDrive/2dsegmentation/'+type+'_*.npy')\n",
        "  string_tensor = tf.Variable(file_names, trainable=False,\n",
        "                              name=name, validate_shape=False)\n",
        "  return string_tensor"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing util.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkkiaIo-Aukg",
        "outputId": "9e5bcb22-ccfe-4a21-c92c-b1e15106923a"
      },
      "source": [
        "!pip install -U tensorflow==1.13.0rc1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.13.0rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/be/80/18adfb46ba0a4044e9feaa0897ceae4673ac07d34deeb74490bc0d4e4987/tensorflow-1.13.0rc1-cp37-cp37m-manylinux1_x86_64.whl (92.7MB)\n",
            "\u001b[K     |████████████████████████████████| 92.7MB 34kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.0rc1) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.0rc1) (1.32.0)\n",
            "Collecting tensorboard<1.13.0,>=1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 39.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.0rc1) (1.1.2)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 49.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.0rc1) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.0rc1) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.0rc1) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.0rc1) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.0rc1) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.0rc1) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.13.0rc1) (3.12.4)\n",
            "Collecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: werkzeug>=0.11.10 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.13.0rc1) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.13.0rc1) (3.3.4)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.0rc1) (56.1.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.0rc1) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.13.0rc1) (4.0.1)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.13.0rc1) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.13.0,>=1.12.0->tensorflow==1.13.0rc1) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMJm1QSr_Yma"
      },
      "source": [
        "!pip install -U scipy==1.2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vssxtbi7EOfK"
      },
      "source": [
        "image_file_image.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bldAuwzxAeE1"
      },
      "source": [
        "%%writefile load_folder_images.py\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import glob\n",
        "import random\n",
        "def _decode_and_preprocess_image(image_file, shift_param = -128, rescale_param = 128, resized_image_size = [128, 128]):\n",
        "  \n",
        "  image = tf.cast(image_file, tf.float32)\n",
        "  \n",
        "  if shift_param != 0:\n",
        "    image = tf.add(image, shift_param)\n",
        "  \n",
        "  if rescale_param != 0:\n",
        "    image = tf.multiply(image, 1.0/rescale_param)\n",
        "  \n",
        "  \n",
        "  \n",
        "  #image = tf.random_crop(image, [32, 32, 3])\n",
        "  print(image.shape)\n",
        "  image = tf.image.resize_images(image, resized_image_size) \n",
        "  print(image.shape)\n",
        "  image.set_shape((resized_image_size[0], resized_image_size[1], 1))\n",
        "  #image = tf.image.grayscasle_to_rgb(image, 'torgb')\n",
        "  return image\n",
        "\n",
        "\n",
        "def _load_images(image_file, batch_size, num_preprocess_threads, min_queue_examples, shift_param = -128, rescale_param = 128, resized_image_size = [128, 128], shuffle = True):\n",
        "  \n",
        "  image = _decode_and_preprocess_image(image_file, shift_param, rescale_param, resized_image_size)\n",
        "  #image = tf.image.grayscasle_to_rgb(image, 'torgb')\n",
        "  images = []\n",
        "  if shuffle == True:\n",
        "    images = tf.train.shuffle_batch(\n",
        "          [image],\n",
        "          batch_size=batch_size,\n",
        "          num_threads=num_preprocess_threads,\n",
        "          capacity=min_queue_examples + 3 * batch_size,\n",
        "          min_after_dequeue=min_queue_examples)\n",
        "  else:\n",
        "    images = tf.train.batch(\n",
        "          [image],\n",
        "          batch_size=batch_size,\n",
        "          num_threads=num_preprocess_threads,\n",
        "          capacity=min_queue_examples + 3 * batch_size)\n",
        "  \n",
        "  \n",
        "  return images\n",
        "\n",
        "def load_image_and_segmentation_from_idlist(idlist_tensor_img, idlist_tensor_seg, batch_size, num_preprocess_threads, min_queue_examples, shift_params = [-128, -0.5], rescale_params = [128, 0.5], resized_image_size = [128, 128], shuffle = True):\n",
        "\n",
        "  filename_queue = random.sample(glob.glob('/content/gdrive/MyDrive/2dsegmentation/'+'image'+'_*.npy'),4)\n",
        "  image_file_image=[]\n",
        "  for path in filename_queue:\n",
        "    image_file_image.append(np.expand_dims(np.resize(np.load(path),(128,128)),-1))\n",
        "  image_file_image=np.stack(image_file_image,0)\n",
        "  image_file_image[image_file_image>250]=250\n",
        "  image_file_image[image_file_image<-200]=-200\n",
        "  image_file_image=(image_file_image-np.mean(image_file_image))/np.std(image_file_image)\n",
        "  processed_image=tf.convert_to_tensor(image_file_image)\n",
        "  processed_image = tf.cast(processed_image, tf.float32)\n",
        "\n",
        "\n",
        "  filename_queue = random.sample(glob.glob('/content/gdrive/MyDrive/2dsegmentation/'+'segmentation'+'_*.npy'),4)\n",
        "  image_file_seg=[]\n",
        "  for path in filename_queue:\n",
        "    image_file_seg.append(np.expand_dims(np.resize(np.load(path),(128,128)),-1))\n",
        "  image_file_seg=np.stack(image_file_seg,0)\n",
        "  processed_seg=tf.convert_to_tensor(image_file_seg)\n",
        "  processed_seg = tf.cast(processed_seg, tf.float32)\n",
        "  \n",
        "  # if shuffle == True:\n",
        "  #   images, segmentations = tf.train.shuffle_batch(\n",
        "  #         [processed_image, processed_seg],\n",
        "  #         batch_size=batch_size,\n",
        "  #         num_threads=num_preprocess_threads,\n",
        "  #         capacity=min_queue_examples + 3 * batch_size,\n",
        "  #         min_after_dequeue=min_queue_examples)\n",
        "  # else:\n",
        "  #   images, segmentations = tf.train.batch(\n",
        "  #         [processed_image, processed_seg],\n",
        "  #         batch_size=batch_size,\n",
        "  #         num_threads=num_preprocess_threads,\n",
        "  #         capacity=min_queue_examples + 3 * batch_size)\n",
        "    \n",
        "  return processed_image, processed_seg\n",
        "  \n",
        "\n",
        "def load_images_from_idlist(idlist, batch_size, num_preprocess_threads, min_queue_examples, shift_param = -128, rescale_param = 128, resized_image_size = [128, 128], shuffle = True):\n",
        "  # Make a queue of file names including all the image files in the relative\n",
        "  # image directory.\n",
        "  filename_queue = tf.train.string_input_producer(idlist,\n",
        "                                                  shuffle=shuffle)\n",
        "  \n",
        "  # Read an entire image file. If the images\n",
        "  # are too large they could be split in advance to smaller files or use the Fixed\n",
        "  # reader to split up the file.\n",
        "  image_reader = tf.WholeFileReader()\n",
        "  \n",
        "  # Read a whole file from the queue, the first returned value in the tuple is the\n",
        "  # filename which we are ignoring.\n",
        "  _, image_file = image_reader.read(filename_queue)\n",
        "\n",
        "  return _load_images(image_file, batch_size, num_preprocess_threads, min_queue_examples, shift_param, rescale_param, resized_image_size, shuffle)\n",
        "\n",
        "def load_images(folder_path_match, batch_size, num_preprocess_threads, min_queue_examples, shift_param = -128, rescale_param = 128, resized_image_size = [128, 128], shuffle = True):\n",
        "  # Make a queue of file names including all the image files in the relative\n",
        "  # image directory.\n",
        "  filename_queue = tf.train.string_input_producer(\n",
        "    tf.train.match_filenames_once(folder_path_match),\n",
        "    shuffle=shuffle)\n",
        "  \n",
        "  # Read an entire image file. If the images\n",
        "  # are too large they could be split in advance to smaller files or use the Fixed\n",
        "  # reader to split up the file.\n",
        "  image_reader = tf.WholeFileReader()\n",
        "  \n",
        "  # Read a whole file from the queue, the first returned value in the tuple is the\n",
        "  # filename which we are ignoring.\n",
        "  _, image_file = image_reader.read(filename_queue)\n",
        "\n",
        "  return _load_images(image_file, batch_size, num_preprocess_threads, min_queue_examples, shift_param, rescale_param, resized_image_size, shuffle)\n",
        "\n",
        "def load_image(image_path, num_preprocess_threads, min_queue_examples, resized_image_size = [64, 64]):\n",
        "  # Make a queue of file names including all the image files in the relative\n",
        "  # image directory.\n",
        "  filename_queue = tf.train.string_input_producer(\n",
        "    tf.train.match_filenames_once(image_path))\n",
        "  \n",
        "  # Read an entire image file. If the images\n",
        "  # are too large they could be split in advance to smaller files or use the Fixed\n",
        "  # reader to split up the file.\n",
        "  image_reader = tf.WholeFileReader()\n",
        "  \n",
        "  # Read a whole file from the queue, the first returned value in the tuple is the\n",
        "  # filename which we are ignoring.\n",
        "  _, image_file = image_reader.read(filename_queue)\n",
        "  \n",
        "  image = tf.image.decode_png(image_file);\n",
        "  \n",
        "  #image.set_shape((32, 32, 3))\n",
        "  \n",
        "  \n",
        "  image = tf.cast(image, tf.float32)\n",
        "  \n",
        "  image = tf.add(image, -128)\n",
        "  image = tf.multiply(image, 1.0/128)\n",
        "  \n",
        "  \n",
        "  \n",
        "  #image = tf.random_crop(image, [32, 32, 3])\n",
        "  image = tf.image.resize_images(image, resized_image_size) \n",
        "  image.set_shape((resized_image_size[0], resized_image_size[1], 1))\n",
        "  #image = tf.image.grayscasle_to_rgb(image, 'torgb')\n",
        "  \n",
        "  images = tf.train.shuffle_batch(\n",
        "      [image],\n",
        "      batch_size=1,\n",
        "      num_threads=num_preprocess_threads,\n",
        "      capacity=min_queue_examples + 3 * 1,\n",
        "      min_after_dequeue=min_queue_examples)\n",
        "  \n",
        "  \n",
        "  \n",
        "  return images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGP_XNCYAl8_"
      },
      "source": [
        "%%writefile dcgan.py\n",
        "import tensorflow as tf\n",
        "\n",
        "def linear(input_tensor, output_dim, scope=None, stddev=1.0):\n",
        "    norm = tf.random_normal_initializer(stddev=stddev)\n",
        "    const = tf.constant_initializer(0.0)\n",
        "    with tf.variable_scope(scope or 'linear'):\n",
        "        w = tf.get_variable('w', [input_tensor.get_shape()[1], output_dim], initializer=norm)\n",
        "        b = tf.get_variable('b', [output_dim], initializer=const)\n",
        "        return tf.matmul(input_tensor, w) + b\n",
        "      \n",
        "def minibatch(input_tensor, num_kernels=256, kernel_dim=4):\n",
        "        in_vec = tf.reshape(input_tensor, [input_tensor.get_shape().as_list()[0], -1])\n",
        "        x = linear(in_vec, num_kernels * kernel_dim, scope='minibatch', stddev=0.02)\n",
        "        activation = tf.reshape(x, (-1, num_kernels, kernel_dim))\n",
        "        diffs = tf.expand_dims(activation, 3) - tf.expand_dims(tf.transpose(activation, [1, 2, 0]), 0)\n",
        "        abs_diffs = tf.reduce_sum(tf.abs(diffs), 2)\n",
        "        minibatch_features = tf.reduce_sum(tf.exp(-abs_diffs), 2)\n",
        "        #minibatch_features = tf.reshape(minibatch_features, (128, 4, 4, -1))\n",
        "        test_out = tf.concat(axis=1, values=[in_vec, minibatch_features])\n",
        "        test_out = tf.reshape(test_out, [input_tensor.get_shape().as_list()[0], input_tensor.get_shape().as_list()[1], input_tensor.get_shape().as_list()[2], -1])\n",
        "        return test_out\n",
        "\n",
        "def disc_conv2d(input_tensor, num_inputs, num_outputs, kernel_size, stride, dropout_ratio, scope):\n",
        "  with tf.variable_scope(scope):\n",
        "              w = tf.get_variable(\n",
        "                        'w',\n",
        "                        [kernel_size, kernel_size, num_inputs, num_outputs],\n",
        "                        tf.float32,\n",
        "                        tf.truncated_normal_initializer(stddev=0.05))\n",
        "              b = tf.get_variable(\n",
        "                  'b',\n",
        "                  [num_outputs],\n",
        "                  tf.float32,\n",
        "                  tf.zeros_initializer())\n",
        "              c = tf.nn.conv2d(input_tensor, w, [1, stride, stride, 1], 'SAME')\n",
        "              mean, variance = tf.nn.moments(c, [0, 1, 2])\n",
        "              outputs = leaky_relu(tf.nn.batch_normalization(c, mean, variance, b, None, 1e-5))\n",
        "              #outputs = tf.nn.dropout(outputs, 0.5)\n",
        "              return outputs;\n",
        "              #out.append(outputs)\n",
        "\n",
        "class Generator:\n",
        "    def __init__(self, depths=[1024, 512, 256, 128, 64], f_size=4):\n",
        "        self.reuse = False\n",
        "        self.f_size = f_size\n",
        "        self.depths = depths + [2]\n",
        "\n",
        "    def model(self, inputs):\n",
        "        i_depth = self.depths[0:(len(self.depths) - 1)]\n",
        "        o_depth = self.depths[1:(len(self.depths))]\n",
        "        out = []\n",
        "        \n",
        "        with tf.variable_scope('g', reuse=self.reuse):\n",
        "            # reshape from inputs\n",
        "            inputs = tf.convert_to_tensor(inputs)\n",
        "            with tf.variable_scope('fc_reshape'):\n",
        "                w0 = tf.get_variable(\n",
        "                    'w',\n",
        "                    [inputs.get_shape()[-1], i_depth[0] * self.f_size * self.f_size],\n",
        "                    tf.float32,\n",
        "                    tf.truncated_normal_initializer(stddev=0.05))\n",
        "                b0 = tf.get_variable(\n",
        "                    'b',\n",
        "                    [i_depth[0]],\n",
        "                    tf.float32,\n",
        "                    tf.zeros_initializer())\n",
        "                fc = tf.matmul(inputs, w0)\n",
        "                reshaped = tf.reshape(fc, [-1, self.f_size, self.f_size, i_depth[0]])\n",
        "                mean, variance = tf.nn.moments(reshaped, [0, 1, 2])\n",
        "                outputs = tf.nn.relu(tf.nn.batch_normalization(reshaped, mean, variance, b0, None, 1e-5))\n",
        "                out.append(outputs)\n",
        "            # deconvolution (transpose of convolution) x 4\n",
        "            \n",
        "            \n",
        "            for i in range(len(self.depths) - 1):\n",
        "                    \n",
        "                with tf.variable_scope('conv%d' % (i + 1)):\n",
        "                    kernel_size = 5\n",
        "    \n",
        "                     \n",
        "                    w = tf.get_variable(\n",
        "                        'w',\n",
        "                        [kernel_size, kernel_size, o_depth[i], i_depth[i]],\n",
        "                        tf.float32,\n",
        "                        tf.truncated_normal_initializer(stddev=0.05))\n",
        "                    b = tf.get_variable(\n",
        "                        'b',\n",
        "                        [o_depth[i]],\n",
        "                        tf.float32,\n",
        "                        tf.zeros_initializer())\n",
        "                    dc = tf.nn.conv2d_transpose(\n",
        "                        outputs,\n",
        "                        w,\n",
        "                        [\n",
        "                            int(outputs.get_shape()[0]),\n",
        "                            self.f_size * 2 ** (i + 1),\n",
        "                            self.f_size * 2 ** (i + 1),\n",
        "                            o_depth[i]\n",
        "                        ],\n",
        "                        [1, 2, 2, 1])\n",
        "                    if i < len(self.depths) - 2:\n",
        "                        mean, variance = tf.nn.moments(dc, [0, 1, 2])\n",
        "                        outputs = tf.nn.relu(tf.nn.batch_normalization(dc, mean, variance, b, None, 1e-5))\n",
        "                    else:\n",
        "                        outputs = tf.nn.bias_add(dc, b)\n",
        "                        outputs = tf.nn.tanh(outputs)\n",
        "                    out.append(outputs)\n",
        "                    \n",
        "        \n",
        "        self.reuse = True\n",
        "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='g')\n",
        "        return out\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        return self.model(inputs)\n",
        "\n",
        "\n",
        "class Discriminator:\n",
        "    def __init__(self, depths=[64, 128, 256, 512]):\n",
        "        self.reuse = False\n",
        "        self.depths = [2] + depths\n",
        "        \n",
        "\n",
        "\n",
        "    def model(self, inputs, return_feature_vector=False):\n",
        "        def leaky_relu(x, leak=0.2):\n",
        "            return tf.maximum(x, x * leak)\n",
        "        i_depth = self.depths[0:(len(self.depths) - 1)]\n",
        "        o_depth = self.depths[1:(len(self.depths))]\n",
        "        out = []\n",
        "        self.weights = []\n",
        "        with tf.variable_scope('d', reuse=self.reuse):\n",
        "            outputs = inputs\n",
        "            # convolution x 4\n",
        "\n",
        "            for i in range(len(self.depths) - 1):\n",
        "                with tf.variable_scope('conv%d' % i):\n",
        "                    w = tf.get_variable(\n",
        "                        'w',\n",
        "                        [5, 5, outputs.get_shape()[3], o_depth[i]],\n",
        "                        tf.float32,\n",
        "                        tf.truncated_normal_initializer(stddev=0.05))\n",
        "                    b = tf.get_variable(\n",
        "                        'b',\n",
        "                        [o_depth[i]],\n",
        "                        tf.float32,\n",
        "                        tf.zeros_initializer())\n",
        "                    c = tf.nn.conv2d(outputs, w, [1, 2, 2, 1], 'SAME')\n",
        "                    mean, variance = tf.nn.moments(c, [0, 1, 2])\n",
        "                    outputs = leaky_relu(tf.nn.batch_normalization(c, mean, variance, b, None, 1e-5))\n",
        "                    \n",
        "                    self.weights.append(w);\n",
        "                    \n",
        "                    out.append(outputs)\n",
        "                    \n",
        "            if(return_feature_vector == True):\n",
        "                return out[3]      \n",
        "            \n",
        "            with tf.variable_scope('classify'):\n",
        "                dim = 1\n",
        "                for d in outputs.get_shape()[1:].as_list():\n",
        "                    dim *= d\n",
        "                    print(dim)\n",
        "                w = tf.get_variable('w', [dim, 2], tf.float32, tf.truncated_normal_initializer(stddev=0.02))\n",
        "                b = tf.get_variable('b', [2], tf.float32, tf.zeros_initializer())\n",
        "                out.append(tf.nn.bias_add(tf.matmul(tf.reshape(outputs, [-1, dim]), w), b))\n",
        "        self.reuse = True\n",
        "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='d')\n",
        "        return out\n",
        "\n",
        "    def __call__(self, inputs, return_feature_vector=False):\n",
        "        return self.model(inputs, return_feature_vector)\n",
        "\n",
        "\n",
        "class DCGAN:\n",
        "    def __init__(self,\n",
        "                 batch_size=128, f_size=2, z_dim=400,\n",
        "                 gdepth1=512, gdepth2=256, gdepth3=128, gdepth4=128,\n",
        "                 ddepth1=128,   ddepth2=128, ddepth3=256, ddepth4=512):\n",
        "        self.batch_size = batch_size\n",
        "        self.f_size = f_size\n",
        "        self.z_dim = z_dim\n",
        "        self.g = Generator(depths=[gdepth1, gdepth2, gdepth3, gdepth4, gdepth4, gdepth4], f_size=self.f_size)\n",
        "        self.d = Discriminator(depths=[ddepth1, ddepth2, ddepth3, ddepth4, ddepth4, ddepth4])\n",
        "        self.z = tf.random_uniform([self.batch_size, self.z_dim], minval=-1.0, maxval=1.0)\n",
        "        self.losses = {\n",
        "            'g': None,\n",
        "            'd': None\n",
        "        }\n",
        "\n",
        "    def build(self, input_images,\n",
        "              learning_rate=0.0004, beta1=0.5, feature_matching=False):\n",
        "        \"\"\"build model, generate losses, train op\"\"\"\n",
        "        generated_images = self.g(self.z)[-1]\n",
        "        print('before d gen')\n",
        "        \n",
        "        outputs_from_g = self.d(generated_images)\n",
        "        \n",
        "        print('before d real')\n",
        "        outputs_from_i = self.d(input_images)\n",
        "        logits_from_g = outputs_from_g[-1]\n",
        "        logits_from_i = outputs_from_i[-1]\n",
        "  \n",
        "        tf.add_to_collection(\n",
        "            'g_losses',\n",
        "            tf.reduce_mean(\n",
        "                tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "                    logits=logits_from_g, labels=tf.ones([self.batch_size], dtype=tf.int64))))\n",
        "        \n",
        "        \n",
        "        d_loss_real = tf.reduce_mean(\n",
        "                tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "                     logits=logits_from_i, labels=tf.ones([self.batch_size], dtype=tf.int64)))\n",
        "        \n",
        "        d_loss_fake = tf.reduce_mean(\n",
        "                tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "                    logits=logits_from_g, labels=tf.zeros([self.batch_size], dtype=tf.int64)))\n",
        "        \n",
        "        tf.add_to_collection(\n",
        "             'd_losses', d_loss_real\n",
        "             )\n",
        "        tf.add_to_collection(\n",
        "            'd_losses',d_loss_fake\n",
        "            )\n",
        "        \n",
        " \n",
        "        \n",
        "        if feature_matching:\n",
        "            features_from_g = tf.reduce_mean(outputs_from_g[-2], axis=(0))\n",
        "            features_from_i = tf.reduce_mean(outputs_from_i[-2], axis=(0))\n",
        "            tf.add_to_collection('g_losses', tf.multiply(tf.nn.l2_loss(features_from_g - features_from_i), 0.1))\n",
        "            mean_image_from_g = tf.reduce_mean(generated_images, axis=(0))\n",
        "            mean_image_from_i = tf.reduce_mean(input_images, axis=(0))\n",
        "            tf.add_to_collection('g_losses', tf.multiply(tf.nn.l2_loss(mean_image_from_g - mean_image_from_i), 0.01))\n",
        "\n",
        "        self.losses['g'] = tf.add_n(tf.get_collection('g_losses'), name='total_g_loss')\n",
        "        self.losses['d'] = tf.add_n(tf.get_collection('d_losses'), name='total_d_loss')\n",
        "        g_opt = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1)\n",
        "        d_opt = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1)\n",
        "\n",
        "        self.g_opt_op = g_opt.minimize(self.losses['g'], var_list=self.g.variables)\n",
        "        self.d_opt_op = d_opt.minimize(self.losses['d'], var_list=self.d.variables)\n",
        "        \n",
        "        with tf.control_dependencies([self.g_opt_op, self.d_opt_op]):\n",
        "            self.train = tf.no_op(name='train')\n",
        "        return self.train\n",
        "\n",
        "    def sample_images(self, row=8, col=8, num_samples = None, inputs=None):\n",
        "        if inputs is None:\n",
        "            inputs = self.z\n",
        "            \n",
        "        if num_samples is None:\n",
        "            num_samples = self.batch_size\n",
        "            \n",
        "        inputs = tf.random_uniform([num_samples, self.z_dim], minval=-1.0, maxval=1.0)\n",
        "        images = tf.cast(tf.multiply(tf.add(self.g(inputs)[-1], 1.0), 127.5), tf.uint8)\n",
        "          \n",
        "        return images\n",
        "        images = [image for image in tf.split(axis=0, num_or_size_splits=self.batch_size, value=images)]\n",
        "        rows = []\n",
        "        for i in range(row):\n",
        "            rows.append(tf.concat(axis=2, values=images[col * i + 0:col * i + col]))\n",
        "        image = tf.concat(axis=1, values=rows)\n",
        "        return tf.image.encode_jpeg(tf.squeeze(image, [0]))\n",
        "      \n",
        "    def retrieve_feature_vector(self, inputs):\n",
        "        vector = tf.reshape(self.d(inputs, return_feature_vector=True), [-1]) \n",
        "        return vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqF-AasuAp37"
      },
      "source": [
        "%%writefile train.py\n",
        "from datetime import datetime\n",
        "import time\n",
        "import glob\n",
        "import tensorflow as tf\n",
        "\n",
        "from dcgan import *\n",
        "import numpy as np \n",
        "from scipy.misc import imsave\n",
        "import load_folder_images\n",
        "import os\n",
        "from load_folder_images import load_image_and_segmentation_from_idlist\n",
        "from load_folder_images import load_image\n",
        "import csv\n",
        "import util\n",
        "\n",
        "FLAGS = tf.app.flags.FLAGS\n",
        "\n",
        "tf.app.flags.DEFINE_string('train_dir', '/tmp/dcgan_train',\n",
        "                           \"\"\"Directory where to write event logs \"\"\"\n",
        "                           \"\"\"and checkpoint.\"\"\")\n",
        "tf.app.flags.DEFINE_integer('max_steps', 100000,\n",
        "                            \"\"\"Number of batches to run.\"\"\")\n",
        "tf.app.flags.DEFINE_boolean('log_device_placement', False,\n",
        "                            \"\"\"Whether to log device placement.\"\"\")\n",
        "\n",
        "tf.app.flags.DEFINE_string(\"working_directory\", \"working_dir\", \"\")\n",
        "tf.app.flags.DEFINE_string(\"checkpoint_dir\", \"checkpoints\", \"\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "z_dim = 100\n",
        "batch_size = 4\n",
        "learning_rate = 0.0004\n",
        "beta1 = 0.5\n",
        "monitoring_batches = 200; #number of batches after which some samples are saved\n",
        "num_monitoring_cycles = 100;\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train():\n",
        "\n",
        "  idlist_img_name = \"list_of_img_ids.txt\"\n",
        "  idlist_seg_name = \"list_of_seg_ids.txt\"\n",
        "  img_folder_path = \"image_folder_path/\"\n",
        "  seg_folder_path = \"segmentation_folder_path/\"\n",
        "\n",
        "  idlist_tensor_img = util.string_tensor_from_idlist_and_path('image')\n",
        "  idlist_tensor_seg = util.string_tensor_from_idlist_and_path('segmentation')\n",
        "  \n",
        "  \n",
        "\n",
        "  images, segmentation_images = load_image_and_segmentation_from_idlist(idlist_tensor_img, idlist_tensor_seg, batch_size, 16, 2560, shift_params = [-128, -0.5], rescale_params = [128, 0.5], shuffle = True)\n",
        "  print(images.shape, segmentation_images.shape)\n",
        "  \n",
        "  dcgan = DCGAN(batch_size)\n",
        "  input_images = images\n",
        "  \n",
        "  input_plus_segmentation = tf.concat([input_images, segmentation_images], 3)\n",
        "  print(input_plus_segmentation.shape)\n",
        "  train_op = dcgan.build(input_plus_segmentation)\n",
        "  print('here')\n",
        "  sample_images = dcgan.sample_images()\n",
        "  print('here')  \n",
        "  saver = tf.train.Saver(max_to_keep = 50)\n",
        "  print('here')\n",
        "\n",
        "  \n",
        "  with tf.Session() as sess:\n",
        "      summary_writer = tf.summary.FileWriter(FLAGS.train_dir, graph=sess.graph)\n",
        "      sess.run(tf.global_variables_initializer())\n",
        "      \n",
        "      \n",
        "      coord = tf.train.Coordinator()\n",
        "      threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
        "      \n",
        "      total_iters_max =  num_monitoring_cycles * monitoring_batches\n",
        "      iters = 0\n",
        "      total_duration = 0.0\n",
        "      avg_iter_time = 0.0\n",
        "      \n",
        "      for cycle in range(num_monitoring_cycles):\n",
        "        for batch in range(monitoring_batches):\n",
        "          start_time = time.time()\n",
        "          _, g_loss_value, d_loss_value = sess.run([train_op, dcgan.losses['g'], dcgan.losses['d']])\n",
        "          _, g_loss_value, d_loss_value = sess.run([dcgan.g_opt_op, dcgan.losses['g'], dcgan.losses['d']])        \n",
        "            \n",
        "          duration = time.time() - start_time\n",
        "          total_duration = total_duration + duration\n",
        "          iters = iters + 1\n",
        "          avg_iter_time = (avg_iter_time * (iters - 1) + duration) / iters\n",
        "          #ETA_seconds = (total_iters_max / iters) * total_duration - total_duration\n",
        "          ETA_seconds = (0.95 * avg_iter_time + 0.05 * duration) * (total_iters_max - iters)\n",
        "          format_str = 'cycle (%d / %d), batch (%d / %d) loss = (G: %.8f, D: %.8f) (%.3f sec/batch) (ETA: %d seconds)'\n",
        "          print(format_str % (cycle, num_monitoring_cycles, batch, monitoring_batches, g_loss_value, d_loss_value, duration, int(ETA_seconds)))\n",
        "        \n",
        "        \n",
        "        checkpoint_folder = FLAGS.working_directory + \"/\" + FLAGS.checkpoint_dir + '/checkpoint%d.ckpt' % cycle\n",
        "        if not os.path.exists(checkpoint_folder):\n",
        "          os.makedirs(checkpoint_folder)\n",
        "        saver.save(sess, checkpoint_folder)\n",
        "\n",
        "\n",
        "        imgs = sess.run(sample_images)\n",
        "         \n",
        "        for k in range(batch_size):\n",
        "            imgs_folder = os.path.join(FLAGS.working_directory, 'out/imgs%d/') % cycle\n",
        "            if not os.path.exists(imgs_folder):\n",
        "              os.makedirs(imgs_folder)\n",
        "              \n",
        "            segs_folder = os.path.join(FLAGS.working_directory, 'out/segs%d/') % cycle\n",
        "            if not os.path.exists(segs_folder):\n",
        "              os.makedirs(segs_folder)\n",
        "              \n",
        "            img_channel = imgs[k][:, :, 0]\n",
        "            img_seg = imgs[k][:, :, 1]\n",
        "            imsave(os.path.join(imgs_folder, 'img_%d.png') % k,\n",
        "                     img_channel.reshape(128, 128))\n",
        "            imsave(os.path.join(segs_folder, 'img_%d.png') % k,\n",
        "                     img_seg.reshape(128, 128))\n",
        "              \n",
        "        imgs_in = sess.run(input_plus_segmentation)    \n",
        "        for k in range(batch_size):\n",
        "          imgs_folder = os.path.join(FLAGS.working_directory, 'in/imgs%d/') % cycle\n",
        "          if not os.path.exists(imgs_folder):\n",
        "            os.makedirs(imgs_folder)\n",
        "            \n",
        "          segs_folder = os.path.join(FLAGS.working_directory, 'in/segs%d/') % cycle\n",
        "          if not os.path.exists(segs_folder):\n",
        "            os.makedirs(segs_folder)\n",
        "\n",
        "          img_channel = imgs_in[k][:, :, 0]\n",
        "          img_seg = imgs_in[k][:, :, 1]\n",
        "          imsave(os.path.join(imgs_folder, 'img_%d.png') % k,\n",
        "                     img_channel.reshape(128, 128))\n",
        "          imsave(os.path.join(segs_folder, 'img_%d.png') % k,\n",
        "                     img_seg.reshape(128, 128))\n",
        "              \n",
        "      coord.request_stop()\n",
        "      coord.join(threads)\n",
        "      \n",
        "     \n",
        "\n",
        "def main(argv=None):  # pylint: disable=unused-argument\n",
        "\n",
        "  \n",
        "  if tf.gfile.Exists(FLAGS.train_dir):\n",
        "    tf.gfile.DeleteRecursively(FLAGS.train_dir)\n",
        "  tf.gfile.MakeDirs(FLAGS.train_dir)\n",
        "  train()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  tf.app.run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrmRMNsFCFOn"
      },
      "source": [
        "!python train.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmcjOgILA7a7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJh-EnPTB4si"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dnYbzUfAyFg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}