{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FE_working_weights.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/gan_segmentation_FE/blob/main/FE_working_weights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkihMbsoz1hZ",
        "outputId": "7fc1b940-6724-47fa-e5cc-7cf8f8fbf6a9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG2pnjJY0ORv"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/gdrive/My Drive/segmentation/Training_Batch1.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhMRVutR0OOe"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "for i in range(5,28):\n",
        "    os.remove( '/content/media/nas/01_Datasets/CT/LITS/Training Batch 1/segmentation-'+str(i)+'.nii')\n",
        "    os.remove( '/content/media/nas/01_Datasets/CT/LITS/Training Batch 1/volume-'+str(i)+'.nii')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJMLGdoI0Ybc",
        "outputId": "19747d40-54bd-4a24-c560-e9472905b568"
      },
      "source": [
        "pip install medpy"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting medpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/70/c1fd5dd60242eee81774696ea7ba4caafac2bad8f028bba94b1af83777d7/MedPy-0.4.0.tar.gz (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 27.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.19.5)\n",
            "Collecting SimpleITK>=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/6b/85df5eb3a8059b23a53a9f224476e75473f9bcc0a8583ed1a9c34619f372/SimpleITK-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (47.4MB)\n",
            "\u001b[K     |████████████████████████████████| 47.4MB 64kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: medpy\n",
            "  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for medpy: filename=MedPy-0.4.0-cp37-cp37m-linux_x86_64.whl size=754469 sha256=f3bc2fcd18766a6614676b90349717f9c4ba46cf48cc520e9153fc09aa55d21d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/c9/9c/2c6281c7a72b9fb1570862a4f028af7ce38405008354fbf870\n",
            "Successfully built medpy\n",
            "Installing collected packages: SimpleITK, medpy\n",
            "Successfully installed SimpleITK-2.0.2 medpy-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRzJyZ270YYk",
        "outputId": "8b95c2be-cc53-4c8d-e4e1-62fadd1e887c"
      },
      "source": [
        "from medpy.io import load, save\n",
        "import os\n",
        "import os.path\n",
        "import gc\n",
        "from scipy.ndimage import zoom\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "try:\n",
        "  os.mkdir('data')\n",
        "except:\n",
        "  pass\n",
        "for file in tqdm(range(5)):\n",
        "        shape=4/2\n",
        "        img, img_header = load('/content/media/nas/01_Datasets/CT/LITS/Training Batch 1/volume-'+str(file)+'.nii')\n",
        "        seg, img_header = load('/content/media/nas/01_Datasets/CT/LITS/Training Batch 1/segmentation-'+str(file)+'.nii')\n",
        "        arr=np.where(seg==2)[-1]\n",
        "        mn=(arr.min()+arr.max())/2\n",
        "        \n",
        "        \n",
        "        if mn-shape<0:\n",
        "          start=0\n",
        "          end=shape*2\n",
        "        elif mn+shape>img.shape[-1]:\n",
        "          end=img.shape[-1]\n",
        "          start=end-shape*2\n",
        "        else:\n",
        "          start=int(max(0,(mn-shape)))\n",
        "          end=int(min(img.shape[-1],int(mn+shape)))\n",
        "        \n",
        "        \n",
        "        img=img[:,:,start:end]\n",
        "        img[img < -200] = -200\n",
        "        img[img > 250] = 250\n",
        "        img+=112\n",
        "        img/=117\n",
        "        img = np.array(img, dtype='float32')\n",
        "        # img = zoom(img, (0.125, 0.125, 1))\n",
        "        # print (\"Saving image \"+str(file))\n",
        "        # np.save( \"/content/data/volume-\" + str(file) ,zoom(img, (0.125, 0.125, 1)))\n",
        "        # print(img.shape)\n",
        "        # del([img])\n",
        "        # gc.collect()\n",
        "        seg=seg.astype('float64')\n",
        "        seg+=0.1645\n",
        "        seg/=0.023138\n",
        "        seg = np.array(seg, dtype='float32')\n",
        "        seg=seg[:,:,start:end]\n",
        "        # print (\"Saving image \"+file)\n",
        "        # seg=zoom(seg, (0.125, 0.125, 1))\n",
        "        total=np.concatenate([img,seg],-1)\n",
        "        print(total.shape)\n",
        "        np.save( \"/content/data/total-\" + str(file),total)\n",
        "        del([seg,img,total])\n",
        "        gc.collect()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 1/5 [00:02<00:10,  2.51s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(512, 512, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 2/5 [00:05<00:08,  2.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(512, 512, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 3/5 [00:20<00:12,  6.46s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(512, 512, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 4/5 [00:28<00:06,  6.73s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(512, 512, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:47<00:00,  9.42s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(512, 512, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmUcIoPe95T6",
        "outputId": "7f7b4e5c-8ca3-4ca7-b404-bc19188b5d06"
      },
      "source": [
        "pip install nilearn"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nilearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/bd/2ad86e2c00ecfe33b86f9f1f6d81de8e11724e822cdf1f5b2d0c21b787f1/nilearn-0.7.1-py3-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 27.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: nibabel>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from nilearn) (3.0.2)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.7/dist-packages (from nilearn) (2.23.0)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19 in /usr/local/lib/python3.7/dist-packages (from nilearn) (0.22.2.post1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (2020.12.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->nilearn) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->nilearn) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.18.0->nilearn) (1.15.0)\n",
            "Installing collected packages: nilearn\n",
            "Successfully installed nilearn-0.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0cF752Iywks"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GB0-ZngUjaA"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk_O1LYAKo1z",
        "outputId": "0f02f3d9-69c7-43ac-d48f-daec6979c7df"
      },
      "source": [
        "%pylab inline\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "from torch import autograd\n",
        "from torch.autograd import Variable\n",
        "import nibabel as nib\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import dataloader\n",
        "from nilearn import plotting\n",
        "\n",
        "\n",
        "BATCH_SIZE=2\n",
        "max_epoch = 100\n",
        "lr = 0.0001\n",
        "gpu = True\n",
        "workers = 4\n",
        "\n",
        "LAMBDA= 10\n",
        "#setting latent variable sizes\n",
        "latent_dim = 1000\n",
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import os\n",
        "from torchvision import transforms\n",
        "from skimage.transform import resize\n",
        "from nilearn import surface\n",
        "from medpy.io import *\n",
        "import glob\n",
        "class ADNIdataset(Dataset):\n",
        "  def __init__(self,range, augmentation=False):\n",
        "    self.augmentation = augmentation\n",
        "    self.name = []\n",
        "    self.range=range\n",
        "    for data in self.range:\n",
        "    \tself.name.append('/content/data/total-'+str(data)+'.npy')\n",
        "    self.name = np.asarray(self.name)\n",
        "\n",
        "  def __len__(self):\n",
        "  \treturn len(self.name)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "  \tpath = self.name[index]\n",
        "  \timg = np.load(path)\n",
        "\n",
        "  \timg = np.flip(img,1)\n",
        "  \timg = np.flip(img,2)\n",
        "  \tsp_size = 64\n",
        "  \timg = resize(img, (sp_size,sp_size,sp_size), mode='constant')\n",
        "  \tif self.augmentation:\n",
        "  \t\trandom_n = torch.rand(1)\n",
        "  \t\trandom_i = 0.3*torch.rand(1)[0]+0.7\n",
        "  \t\tif random_n[0] > 0.5:\n",
        "  \t\t\timg = np.flip(img,0)\n",
        "                \n",
        "  \t\timg = img*random_i.data.cpu().numpy()\n",
        "            \n",
        "  \timageout = torch.from_numpy(img).float().view(1,sp_size,sp_size,sp_size)\n",
        "  \timageout = imageout*2-1\n",
        "\n",
        "  \treturn imageout\n",
        "\n",
        "def calc_gradient_penalty(netD, real_data, fake_data):    \n",
        "    alpha = torch.rand(real_data.size(0),1,1,1,1)\n",
        "    alpha = alpha.expand(real_data.size())\n",
        "    \n",
        "    alpha = alpha.cuda()\n",
        "\n",
        "    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
        "\n",
        "    interpolates = interpolates.cuda()\n",
        "    interpolates = Variable(interpolates, requires_grad=True)\n",
        "\n",
        "    disc_interpolates = netD(interpolates)\n",
        "\n",
        "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
        "                              grad_outputs=torch.ones(disc_interpolates.size()).cuda(),\n",
        "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n",
        "    return gradient_penalty\n",
        "def inf_train_gen(data_loader):\n",
        "    while True:\n",
        "        for _,images in enumerate(data_loader):\n",
        "            yield images"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['load', 'save', 'Generator', 'shape']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n",
            "/usr/local/lib/python3.7/dist-packages/nilearn/datasets/__init__.py:90: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
            "  \"Numpy arrays.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHzvgma0TM59"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, channel=512):\n",
        "        super(Discriminator, self).__init__()        \n",
        "        self.channel = channel\n",
        "        n_class = 1\n",
        "        \n",
        "        self.conv1 = nn.Conv3d(1, channel//8, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv3d(channel//8, channel//4, kernel_size=4, stride=2, padding=1)\n",
        "        self.bn2 = nn.BatchNorm3d(channel//4)\n",
        "        self.conv3 = nn.Conv3d(channel//4, channel//2, kernel_size=4, stride=2, padding=1)\n",
        "        self.bn3 = nn.BatchNorm3d(channel//2)\n",
        "        self.conv4 = nn.Conv3d(channel//2, channel, kernel_size=4, stride=2, padding=1)\n",
        "        self.bn4 = nn.BatchNorm3d(channel)\n",
        "        \n",
        "        self.conv5 = nn.Conv3d(channel, n_class, kernel_size=4, stride=2, padding=1)\n",
        "        \n",
        "    def forward(self, x, _return_activations=False):\n",
        "        h1 = F.leaky_relu(self.conv1(x), negative_slope=0.2)\n",
        "        h2 = F.leaky_relu(self.bn2(self.conv2(h1)), negative_slope=0.2)\n",
        "        h3 = F.leaky_relu(self.bn3(self.conv3(h2)), negative_slope=0.2)\n",
        "        h4 = F.leaky_relu(self.bn4(self.conv4(h3)), negative_slope=0.2)\n",
        "        h5 = self.conv5(h4)\n",
        "        output = h5\n",
        "\n",
        "        return output\n",
        "    \n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise:int=1000, channel:int=64):\n",
        "        super(Generator, self).__init__()\n",
        "        _c = channel\n",
        "        \n",
        "        self.noise = noise\n",
        "        self.fc = nn.Linear(1000,512*4*4*4)\n",
        "        self.bn1 = nn.BatchNorm3d(_c*8)\n",
        "        \n",
        "        self.tp_conv2 = nn.Conv3d(_c*8, _c*4, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm3d(_c*4)\n",
        "        \n",
        "        self.tp_conv3 = nn.Conv3d(_c*4, _c*2, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm3d(_c*2)\n",
        "        \n",
        "        self.tp_conv4 = nn.Conv3d(_c*2, _c, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn4 = nn.BatchNorm3d(_c)\n",
        "        \n",
        "        self.tp_conv5 = nn.Conv3d(_c, 1, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        \n",
        "    def forward(self, noise):\n",
        "        noise = noise.view(-1, 1000)\n",
        "        h = self.fc(noise)\n",
        "        h = h.view(-1,512,4,4,4)\n",
        "        h = F.relu(self.bn1(h))\n",
        "\n",
        "        h = F.upsample(h,scale_factor = 2)\n",
        "        h = self.tp_conv2(h)\n",
        "        h = F.relu(self.bn2(h))\n",
        "        \n",
        "        h = F.upsample(h,scale_factor = 2)\n",
        "        h = self.tp_conv3(h)\n",
        "        h = F.relu(self.bn3(h))\n",
        "\n",
        "        h = F.upsample(h,scale_factor = 2)\n",
        "        h = self.tp_conv4(h)\n",
        "        h = F.relu(self.bn4(h))\n",
        "\n",
        "        h = F.upsample(h,scale_factor = 2)\n",
        "        h = self.tp_conv5(h)\n",
        "\n",
        "        h = F.tanh(h)\n",
        "\n",
        "        return h"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viwzmKOwypBn",
        "outputId": "5e09e27f-9010-4668-ba9a-61915e7d7aea"
      },
      "source": [
        "trainset1 = ADNIdataset(list(range(3)),augmentation=True)\n",
        "train_loader1 = torch.utils.data.DataLoader(trainset1,batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True,num_workers=workers)\n",
        "trainset2 = ADNIdataset(list(range(3,5)),augmentation=True)\n",
        "train_loader2 = torch.utils.data.DataLoader(trainset2,batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True,num_workers=workers)\n",
        "\n",
        "\n",
        "\n",
        "D1 = Discriminator().cuda()\n",
        "G1 = Generator().cuda()\n",
        "a=torch.load('/content/gdrive/MyDrive/segmentation/WGAN_G(1).pth',map_location='cuda:0')\n",
        "G1.load_state_dict(a)\n",
        "g_optimizer1 = optim.Adam(G1.parameters(), lr=0.0002)\n",
        "d_optimizer1 = optim.Adam(D1.parameters(), lr=0.0002)\n",
        "\n",
        "\n",
        "D2 = Discriminator().cuda()\n",
        "G2 = Generator().cuda()\n",
        "G2.load_state_dict(a)\n",
        "g_optimizer2 = optim.Adam(G2.parameters(), lr=0.0002)\n",
        "d_optimizer2 = optim.Adam(D2.parameters(), lr=0.0002)\n",
        "\n",
        "\n",
        "D_org = Discriminator().cuda()\n",
        "G_org = Generator().cuda()\n",
        "\n",
        "real_y = Variable(torch.ones((BATCH_SIZE, 1)).cuda())\n",
        "fake_y = Variable(torch.zeros((BATCH_SIZE, 1)).cuda())\n",
        "loss_f = nn.BCELoss()\n",
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouha8o3NTDvm"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seuR-gSJLF0u"
      },
      "source": [
        "Ds=[D1,D2]\n",
        "Gs=[G1,G2]\n",
        "train_loaders=[inf_train_gen(train_loader1),inf_train_gen(train_loader2)]\n",
        "d_optimizers=[d_optimizer1,d_optimizer2]\n",
        "g_optimizers=[g_optimizer1,g_optimizer2]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1y95glPM1vZ",
        "outputId": "d7d1751f-ff6a-4d09-9502-9af95c4e1dd3"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import torch.distributions as tdist\n",
        "TOTAL_ITER = 200000\n",
        "pace=1\n",
        "for iteration in tqdm(range(TOTAL_ITER)):\n",
        "  for num in range(2):\n",
        "    ###############################################\n",
        "    # Train D \n",
        "    ###############################################\n",
        "    d_optimizer=d_optimizers[num]\n",
        "    g_optimizer=g_optimizers[num]\n",
        "    D=Ds[num]\n",
        "    G=Gs[num]\n",
        "    for p in D.parameters():  \n",
        "        p.requires_grad = True \n",
        "\n",
        "    real_images = train_loaders[num].__next__()\n",
        "    if real_images.shape[0]==1:\n",
        "      real_images = train_loaders[num].__next__()\n",
        "      \n",
        "    D.zero_grad()\n",
        "    real_images = Variable(real_images).cuda()\n",
        "\n",
        "    _batch_size = real_images.size(0)\n",
        "\n",
        "\n",
        "    y_real_pred = D(real_images)\n",
        "\n",
        "    d_real_loss = y_real_pred.mean()\n",
        "    \n",
        "    noise = Variable(torch.randn((_batch_size, latent_dim, 1, 1, 1)),volatile=True).cuda()\n",
        "    fake_images = G(noise)\n",
        "    y_fake_pred = D(fake_images.detach())\n",
        "\n",
        "    d_fake_loss = y_fake_pred.mean()\n",
        "\n",
        "    gradient_penalty = calc_gradient_penalty(D,real_images.data, fake_images.data)\n",
        " \n",
        "    d_loss = - d_real_loss + d_fake_loss +gradient_penalty\n",
        "    d_loss.backward()\n",
        "    Wasserstein_D = d_real_loss - d_fake_loss\n",
        "\n",
        "    d_optimizer.step()\n",
        "\n",
        "    ###############################################\n",
        "    # Train G \n",
        "    ###############################################\n",
        "    for p in D.parameters():\n",
        "        p.requires_grad = False\n",
        "        \n",
        "    for iters in range(5):\n",
        "        G.zero_grad()\n",
        "        noise = Variable(torch.randn((_batch_size, latent_dim, 1, 1 ,1)).cuda())\n",
        "        fake_image =G(noise)\n",
        "        y_fake_g = D(fake_image)\n",
        "\n",
        "        g_loss = -y_fake_g.mean()\n",
        "\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "  device='cuda'\n",
        "  if iteration%pace ==0:\n",
        "    with torch.no_grad():\n",
        "        for key in D_org.state_dict().keys():\n",
        "            \n",
        "            if Ds[0].state_dict()[key].dtype == torch.int64:\n",
        "                D_org.state_dict()[key].data.copy_(Ds[0].state_dict()[key])\n",
        "            else:\n",
        "                temp = torch.zeros_like(D_org.state_dict()[key])\n",
        "                for s in range(2):\n",
        "                    try:\n",
        "                      nn = tdist.Normal(torch.tensor([0.0]), 1e-3*torch.std(Ds[s].state_dict()[key].detach().cpu()))\n",
        "                    except:\n",
        "                      nn = tdist.Normal(torch.tensor([0.0]), 1e-3*1e-3)\n",
        "                    shape=Ds[s].state_dict()[key].shape\n",
        "                    noise = nn.sample(shape).reshape(shape)\n",
        "                    noise = noise.to(device)\n",
        "                    if s==0:\n",
        "                      t_noise=noise\n",
        "                    else:\n",
        "                      t_noise+=noise\n",
        "                    temp += 0.5*(Ds[s].state_dict()[key]+noise)\n",
        "                D_org.state_dict()[key].data.copy_(temp)\n",
        "                \n",
        "                \n",
        "                for s in range(2):\n",
        "                        Ds[s].state_dict()[key].data.copy_(D_org.state_dict()[key])\n",
        "\n",
        "\n",
        "\n",
        "        for key in G_org.state_dict().keys():\n",
        "            if Gs[0].state_dict()[key].dtype == torch.int64:\n",
        "                G_org.state_dict()[key].data.copy_(Gs[0].state_dict()[key])\n",
        "            else:\n",
        "                temp = torch.zeros_like(G_org.state_dict()[key])\n",
        "                for s in range(2):\n",
        "                    try:\n",
        "                      nn = tdist.Normal(torch.tensor([0.0]), 1e-3*torch.std(Gs[s].state_dict()[key].detach().cpu()))\n",
        "                    except:\n",
        "                      nn = tdist.Normal(torch.tensor([0.0]), 1e-3*1e-3)\n",
        "                    shape=Gs[s].state_dict()[key].shape\n",
        "                    noise = nn.sample(shape).reshape(shape)\n",
        "                    noise = noise.to(device)\n",
        "                    if s==0:\n",
        "                      t_noise=noise\n",
        "                    else:\n",
        "                      t_noise+=noise\n",
        "                    temp += 0.5*(Gs[s].state_dict()[key]+noise)\n",
        "                G_org.state_dict()[key].data.copy_(temp)\n",
        "                for s in range(2):\n",
        "                        Gs[s].state_dict()[key].data.copy_(G_org.state_dict()[key])\n",
        "        \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/200000 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1698: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 1/200000 [00:05<290:05:15,  5.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 2/200000 [00:10<289:31:37,  5.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 3/200000 [00:15<288:56:51,  5.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 4/200000 [00:20<289:30:00,  5.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 5/200000 [00:26<290:03:08,  5.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 6/200000 [00:31<290:23:27,  5.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 7/200000 [00:36<289:37:14,  5.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjc8P1M5ErCM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1AgohhiEq_k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcAB97LoEq9H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}