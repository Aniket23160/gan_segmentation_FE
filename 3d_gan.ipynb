{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3d_gan.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMLuske+Ni3wxumTZaaiJGE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/gan_segmentation_FE/blob/main/3d_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue-2UyyF-OhA",
        "outputId": "a4533145-c8f9-4075-b853-c53dd45f157d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIZy3F12Eal9"
      },
      "source": [
        "# import zipfile\n",
        "# with zipfile.ZipFile('/content/gdrive/My Drive/segmentation/Training_Batch1.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('/content/')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0Slma5-EcMg"
      },
      "source": [
        "# pip install medpy"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDRr7J9IEhUz"
      },
      "source": [
        "# import os\n",
        "# import glob\n",
        "# for i in range(6,28):\n",
        "#     os.remove( '/content/media/nas/01_Datasets/CT/LITS/Training Batch 1/segmentation-'+str(i)+'.nii')\n",
        "#     os.remove( '/content/media/nas/01_Datasets/CT/LITS/Training Batch 1/volume-'+str(i)+'.nii')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SFK5wr3F95L"
      },
      "source": [
        "# from medpy.io import load, save\n",
        "# def app(img):\n",
        "#   img[img < -200] = -200\n",
        "#   img[img > 250] = 250\n",
        "#   return img\n",
        "# img1, img_header1 = load('/content/media/nas/01_Datasets/CT/LITS/Training Batch 1/segmentation-0.nii')\n",
        "# img2, img_header1 = load('/content/media/nas/01_Datasets/CT/LITS/Training Batch 1/segmentation-1.nii')\n",
        "# img3, img_header1 = load('/content/media/nas/01_Datasets/CT/LITS/Training Batch 1/segmentation-2.nii')\n",
        "# img4, img_header1 = load('/content/media/nas/01_Datasets/CT/LITS/Training Batch 1/segmentation-3.nii')\n",
        "# img5, img_header1 = load('/content/media/nas/01_Datasets/CT/LITS/Training Batch 1/segmentation-4.nii')\n",
        "# img6, img_header1 = load('/content/media/nas/01_Datasets/CT/LITS/Training Batch 1/segmentation-5.nii')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5nYp_EVEw8Q"
      },
      "source": [
        "# from medpy.io import load, save\n",
        "# import os\n",
        "# import os.path\n",
        "# import gc\n",
        "# import numpy as np\n",
        "# from tqdm import tqdm\n",
        "# for file in tqdm(range(6)):\n",
        "#         img, img_header = load('/content/media/nas/01_Datasets/CT/LITS/Training Batch 1/volume-'+str(file)+'.nii')\n",
        "#         img[img < -200] = -200\n",
        "#         img[img > 250] = 250\n",
        "#         img+=112\n",
        "#         img/=117\n",
        "#         img = np.array(img, dtype='float32')\n",
        "#         print (\"Saving image \"+str(file))\n",
        "#         np.save( \"/content/data/volume-\" + str(file) ,img)\n",
        "#         print(img.shape)\n",
        "#         del([img])\n",
        "#         gc.collect()\n",
        "#         img, img_header = load('/content/media/nas/01_Datasets/CT/LITS/Training Batch 1/segmentation-'+str(file)+'.nii')\n",
        "#         img=img.astype('float64')\n",
        "#         img+=0.1645\n",
        "#         img/=0.023138\n",
        "#         img = np.array(img, dtype='float32')\n",
        "#         # print (\"Saving image \"+file)\n",
        "#         np.save( \"/content/data/segmentation-\" + str(file),img )\n",
        "#         del([img])\n",
        "#         gc.collect()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vohe2KegSLH7"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9fHd2tT_hso"
      },
      "source": [
        "import scipy.ndimage as nd\n",
        "import scipy.io as io\n",
        "import matplotlib\n",
        "# Force matplotlib to not use any Xwindows backend.\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.measure as sk\n",
        "from mpl_toolkits import mplot3d\n",
        "import matplotlib.gridspec as gridspec\n",
        "import numpy as np\n",
        "from torch.utils import data\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "def getVoxelFromMat(path, cube_len=64):\n",
        "\n",
        "    voxels = io.loadmat(path)['instance']\n",
        "    voxels = np.pad(voxels, (1, 1), 'constant', constant_values=(0, 0))\n",
        "    if cube_len != 32 and cube_len == 64:\n",
        "        voxels = nd.zoom(voxels, (2, 2, 2), mode='constant', order=0)\n",
        "    return voxels\n",
        "\n",
        "\n",
        "def getVFByMarchingCubes(voxels, threshold=0.5):\n",
        "    \"\"\"Voxel 로 부터 Vertices, faces 리턴 하는 함수\"\"\"\n",
        "    v, f = sk.marching_cubes_classic(voxels, level=threshold)\n",
        "    return v, f\n",
        "\n",
        "\n",
        "def plotVoxelVisdom(voxels, visdom, title):\n",
        "    v, f = getVFByMarchingCubes(voxels)\n",
        "    visdom.mesh(X=v, Y=f, opts=dict(opacity=0.5, title=title))\n",
        "\n",
        "\n",
        "def plotFromVoxels(voxels):\n",
        "    z, x, y = voxels.nonzero()\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "    ax.scatter(x, y, -z, zdir='z', c='red')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def SavePloat_Voxels(voxels, path, iteration):\n",
        "    voxels = voxels[:8].__ge__(0.5)\n",
        "    fig = plt.figure(figsize=(32, 16))\n",
        "    gs = gridspec.GridSpec(2, 4)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "    for i, sample in enumerate(voxels):\n",
        "        x, y, z = sample.nonzero()\n",
        "        ax = plt.subplot(gs[i], projection='3d')\n",
        "        ax.scatter(x, y, z, zdir='z', c='red')\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect('equal')\n",
        "    plt.savefig(path + '/{}.png'.format(str(iteration).zfill(3)), bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "    with open(path + '/{}.pkl'.format(str(iteration).zfill(3)), \"wb\") as f:\n",
        "        pickle.dump(voxels, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "def make_hyparam_string(hyparam_dict):\n",
        "    str_result = \"\"\n",
        "    for i in hyparam_dict.keys():\n",
        "        str_result = str_result + str(i) + \"=\" + str(hyparam_dict[i]) + \"_\"\n",
        "    return str_result[:-1]\n",
        "\n",
        "class ShapeNetDataset(data.Dataset):\n",
        "    \"\"\"Custom Dataset compatible with torch.utils.data.DataLoader\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "      pass\n",
        "    def __getitem__(self, index):\n",
        "        seg=np.load('/content/data/segmentation-'+str(index)+'.npy')\n",
        "        img=np.load('/content/data/volume-'+str(index)+'.npy')\n",
        "        total=np.concatenate([img,seg],-1)\n",
        "\n",
        "        return torch.FloatTensor(total)\n",
        "\n",
        "    def __len__(self):\n",
        "        return 6\n",
        "\n",
        "def var_or_cuda(x):\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "    return Variable(x)\n",
        "\n",
        "def generateZ():\n",
        "\n",
        "    Z = var_or_cuda(torch.Tensor(1,1024).normal_(0, 0.33))\n",
        "\n",
        "    return Z\n",
        "\n",
        "########################## Pickle helper ###############################\n",
        "\n",
        "\n",
        "def read_pickle(path, G, G_solver, D_, D_solver):\n",
        "    try:\n",
        "\n",
        "        files = os.listdir(path)\n",
        "        file_list = [int(file.split('_')[-1].split('.')[0]) for file in files]\n",
        "        file_list.sort()\n",
        "        recent_iter = str(file_list[-1])\n",
        "        print(recent_iter, path)\n",
        "\n",
        "        with open(path + \"/G_\" + recent_iter + \".pkl\", \"rb\") as f:\n",
        "            G.load_state_dict(torch.load(f))\n",
        "        with open(path + \"/G_optim_\" + recent_iter + \".pkl\", \"rb\") as f:\n",
        "            G_solver.load_state_dict(torch.load(f))\n",
        "        with open(path + \"/D_\" + recent_iter + \".pkl\", \"rb\") as f:\n",
        "            D_.load_state_dict(torch.load(f))\n",
        "        with open(path + \"/D_optim_\" + recent_iter + \".pkl\", \"rb\") as f:\n",
        "            D_solver.load_state_dict(torch.load(f))\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "\n",
        "        print(\"fail try read_pickle\", e)\n",
        "\n",
        "\n",
        "\n",
        "def save_new_pickle(path, iteration, G, G_solver, D_, D_solver):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "    with open(path + \"/G_\" + str(iteration) + \".pkl\", \"wb\") as f:\n",
        "        torch.save(G.state_dict(), f)\n",
        "    with open(path + \"/G_optim_\" + str(iteration) + \".pkl\", \"wb\") as f:\n",
        "        torch.save(G_solver.state_dict(), f)\n",
        "    with open(path + \"/D_\" + str(iteration) + \".pkl\", \"wb\") as f:\n",
        "        torch.save(D_.state_dict(), f)\n",
        "    with open(path + \"/D_optim_\" + str(iteration) + \".pkl\", \"wb\") as f:\n",
        "        torch.save(D_solver.state_dict(), f)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiQgn7rK_oAX"
      },
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "class _G(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(_G, self).__init__()\n",
        "        self.cube_len = 512\n",
        "\n",
        "        padd = (0, 0, 0)\n",
        "        if self.cube_len == 32:\n",
        "            padd = (1,1,1)\n",
        "\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.ConvTranspose3d(1024, self.cube_len*8, kernel_size=4, stride=2, padding=padd),\n",
        "            torch.nn.BatchNorm3d(self.cube_len*8),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.ConvTranspose3d(self.cube_len*8, self.cube_len*4, kernel_size=4, stride=2, padding=(1, 1, 1)),\n",
        "            torch.nn.BatchNorm3d(self.cube_len*4),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "        self.layer3 = torch.nn.Sequential(\n",
        "            torch.nn.ConvTranspose3d(self.cube_len*4, self.cube_len*2, kernel_size=4, stride=2, padding=(1, 1, 1)),\n",
        "            torch.nn.BatchNorm3d(self.cube_len*2),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "        self.layer4 = torch.nn.Sequential(\n",
        "            torch.nn.ConvTranspose3d(self.cube_len*2, self.cube_len, kernel_size=4, stride=2, padding=(1, 1, 1)),\n",
        "            torch.nn.BatchNorm3d(self.cube_len),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "        self.layer5 = torch.nn.Sequential(\n",
        "            torch.nn.ConvTranspose3d(self.cube_len, 1, kernel_size=4, stride=2, padding=(1, 1, 1))\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x.view(-1, 1024, 1, 1, 1)\n",
        "        #print(out.size())  # torch.Size([100, 200, 1, 1, 1])\n",
        "        out = self.layer1(out)\n",
        "        #print(out.size())  # torch.Size([100, 512, 4, 4, 4])\n",
        "        out = self.layer2(out)\n",
        "        #print(out.size())  # torch.Size([100, 256, 8, 8, 8])\n",
        "        out = self.layer3(out)\n",
        "        #print(out.size())  # torch.Size([100, 128, 16, 16, 16])\n",
        "        out = self.layer4(out)\n",
        "        #print(out.size())  # torch.Size([100, 64, 32, 32, 32])\n",
        "        out = self.layer5(out)\n",
        "        #print(out.size())  # torch.Size([100, 1, 64, 64, 64])\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class _D(torch.nn.Module):\n",
        "    def __init__(self, ):\n",
        "        super(_D, self).__init__()\n",
        "        self.cube_len = 512\n",
        "\n",
        "        padd = (0,0,0)\n",
        "        if self.cube_len == 32:\n",
        "            padd = (1,1,1)\n",
        "\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv3d(1, self.cube_len, kernel_size=4, stride=2,  padding=(1, 1, 1)),\n",
        "            torch.nn.BatchNorm3d(self.cube_len),\n",
        "            torch.nn.LeakyReLU(0.1)\n",
        "        )\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv3d(self.cube_len, self.cube_len*2, kernel_size=4, stride=2,  padding=(1, 1, 1)),\n",
        "            torch.nn.BatchNorm3d(self.cube_len*2),\n",
        "            torch.nn.LeakyReLU(0.1)\n",
        "        )\n",
        "        self.layer3 = torch.nn.Sequential(\n",
        "            torch.nn.Conv3d(self.cube_len*2, self.cube_len*4, kernel_size=4, stride=2,  padding=(1, 1, 1)),\n",
        "            torch.nn.BatchNorm3d(self.cube_len*4),\n",
        "            torch.nn.LeakyReLU(0.1)\n",
        "        )\n",
        "        self.layer4 = torch.nn.Sequential(\n",
        "            torch.nn.Conv3d(self.cube_len*4, self.cube_len*8, kernel_size=4, stride=2,  padding=(1, 1, 1)),\n",
        "            torch.nn.BatchNorm3d(self.cube_len*8),\n",
        "            torch.nn.LeakyReLU(0.1)\n",
        "        )\n",
        "        self.layer5 = torch.nn.Sequential(\n",
        "            torch.nn.Conv3d(self.cube_len*8, 1, kernel_size=4, stride=2, padding=padd),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x.view(-1, 1, 512,512,512)\n",
        "        #print(out.size()) # torch.Size([100, 1, 64, 64, 64])\n",
        "        out = self.layer1(out)\n",
        "        #print(out.size())  # torch.Size([100, 64, 32, 32, 32])\n",
        "        out = self.layer2(out)\n",
        "        #print(out.size())  # torch.Size([100, 128, 16, 16, 16])\n",
        "        out = self.layer3(out)\n",
        "        #print(out.size())  # torch.Size([100, 256, 8, 8, 8])\n",
        "        out = self.layer4(out)\n",
        "        #print(out.size())  # torch.Size([100, 512, 4, 4, 4])\n",
        "        out = self.layer5(out)\n",
        "        #print(out.size())  # torch.Size([100, 200, 1, 1, 1])\n",
        "\n",
        "        return out"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUbiPEhX_wX3"
      },
      "source": [
        "from bisect import bisect_right\n",
        "from torch.optim.optimizer import Optimizer\n",
        "\n",
        "\n",
        "class _LRScheduler(object):\n",
        "    def __init__(self, optimizer, last_epoch=-1):\n",
        "        if not isinstance(optimizer, Optimizer):\n",
        "            raise TypeError('{} is not an Optimizer'.format(\n",
        "                type(optimizer).__name__))\n",
        "        self.optimizer = optimizer\n",
        "        if last_epoch == -1:\n",
        "            for group in optimizer.param_groups:\n",
        "                group.setdefault('initial_lr', group['lr'])\n",
        "        else:\n",
        "            for i, group in enumerate(optimizer.param_groups):\n",
        "                if 'initial_lr' not in group:\n",
        "                    raise KeyError(\"param 'initial_lr' is not specified \"\n",
        "                                   \"in param_groups[{}] when resuming an optimizer\".format(i))\n",
        "        self.base_lrs = list(map(lambda group: group['initial_lr'], optimizer.param_groups))\n",
        "        self.step(last_epoch + 1)\n",
        "        self.last_epoch = last_epoch\n",
        "\n",
        "    def get_lr(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def step(self, epoch=None):\n",
        "        if epoch is None:\n",
        "            epoch = self.last_epoch + 1\n",
        "        self.last_epoch = epoch\n",
        "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "\n",
        "class LambdaLR(_LRScheduler):\n",
        "    def __init__(self, optimizer, lr_lambda, last_epoch=-1):\n",
        "        self.optimizer = optimizer\n",
        "        if not isinstance(lr_lambda, list) and not isinstance(lr_lambda, tuple):\n",
        "            self.lr_lambdas = [lr_lambda] * len(optimizer.param_groups)\n",
        "        else:\n",
        "            if len(lr_lambda) != len(optimizer.param_groups):\n",
        "                raise ValueError(\"Expected {} lr_lambdas, but got {}\".format(\n",
        "                    len(optimizer.param_groups), len(lr_lambda)))\n",
        "            self.lr_lambdas = list(lr_lambda)\n",
        "        self.last_epoch = last_epoch\n",
        "        super(LambdaLR, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        return [base_lr * lmbda(self.last_epoch)\n",
        "                for lmbda, base_lr in zip(self.lr_lambdas, self.base_lrs)]\n",
        "\n",
        "\n",
        "class StepLR(_LRScheduler):\n",
        "    \"\"\"Sets the learning rate of each parameter group to the initial lr\n",
        "    decayed by gamma every step_size epochs.\n",
        "    Args:\n",
        "        optimizer (Optimizer): Wrapped optimizer.\n",
        "        step_size (int): Period of learning rate decay.\n",
        "        gamma (float): Multiplicative factor of learning rate decay.\n",
        "    Example:\n",
        "        >>> # Assuming optimizer uses lr = 0.5 for all groups\n",
        "        >>> # lr = 0.05     if epoch < 30\n",
        "        >>> # lr = 0.005    if 30 <= epoch < 60\n",
        "        >>> # lr = 0.0005   if 60 <= epoch < 90\n",
        "        >>> # ...\n",
        "        >>> scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "        >>> for epoch in range(100):\n",
        "        >>>     scheduler.step()\n",
        "        >>>     train(...)\n",
        "        >>>     validate(...)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, step_size, gamma=0.1, last_epoch=-1):\n",
        "        self.step_size = step_size\n",
        "        self.gamma = gamma\n",
        "        super(StepLR, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        return [base_lr * self.gamma ** (self.last_epoch // self.step_size)\n",
        "                for base_lr in self.base_lrs]\n",
        "\n",
        "\n",
        "class MultiStepLR(_LRScheduler):\n",
        "    \"\"\"Set the learning rate of each parameter group to the initial lr decayed\n",
        "    by gamma once the number of epoch reaches one of the milestones.\n",
        "    Args:\n",
        "        optimizer (Optimizer): Wrapped optimizer.\n",
        "        milestones (list): List of epoch indices. Must be increasing.\n",
        "        gamma (float): Multiplicative factor of learning rate decay.\n",
        "    Example:\n",
        "        >>> # Assuming optimizer uses lr = 0.5 for all groups\n",
        "        >>> # lr = 0.05     if epoch < 30\n",
        "        >>> # lr = 0.005    if 30 <= epoch < 80\n",
        "        >>> # lr = 0.0005   if epoch >= 80\n",
        "        >>> scheduler = MultiStepLR(optimizer, milestones=[30,80], gamma=0.1)\n",
        "        >>> for epoch in range(100):\n",
        "        >>>     scheduler.step()\n",
        "        >>>     train(...)\n",
        "        >>>     validate(...)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, milestones, gamma=0.1, last_epoch=-1):\n",
        "        if not list(milestones) == sorted(milestones):\n",
        "            raise ValueError('Milestones should be a list of'\n",
        "                             ' increasing integers. Got {}', milestones)\n",
        "        self.milestones = milestones\n",
        "        self.gamma = gamma\n",
        "        super(MultiStepLR, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        return [base_lr * self.gamma ** bisect_right(self.milestones, self.last_epoch)\n",
        "                for base_lr in self.base_lrs]\n",
        "\n",
        "\n",
        "class ExponentialLR(_LRScheduler):\n",
        "    \"\"\"Set the learning rate of each parameter group to the initial lr decayed\n",
        "    by gamma every epoch.\n",
        "    Args:\n",
        "        optimizer (Optimizer): Wrapped optimizer.\n",
        "        gamma (float): Multiplicative factor of learning rate decay.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, gamma, last_epoch=-1):\n",
        "        self.gamma = gamma\n",
        "        super(ExponentialLR, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "    def get_lr(self):\n",
        "        return [base_lr * self.gamma ** self.last_epoch\n",
        "                for base_lr in self.base_lrs]\n",
        "\n",
        "\n",
        "class ReduceLROnPlateau(object):\n",
        "    \"\"\"Reduce learning rate when a metric has stopped improving.\n",
        "    Models often benefit from reducing the learning rate by a factor\n",
        "    of 2-10 once learning stagnates. This scheduler reads a metrics\n",
        "    quantity and if no improvement is seen for a 'patience' number\n",
        "    of epochs, the learning rate is reduced.\n",
        "    Args:\n",
        "        optimizer (Optimizer): Wrapped optimizer.\n",
        "        mode (str): One of `min`, `max`. In `min` mode, lr will\n",
        "            be reduced when the quantity monitored has stopped\n",
        "            decreasing; in `max` mode it will be reduced when the\n",
        "            quantity monitored has stopped increasing. Default: 'min'.\n",
        "        factor (float): Factor by which the learning rate will be\n",
        "            reduced. new_lr = lr * factor. Default: 0.1.\n",
        "        patience (int): Number of epochs with no improvement after\n",
        "            which learning rate will be reduced. Default: 10.\n",
        "        verbose (bool): If True, prints a message to stdout for\n",
        "            each update. Default: False.\n",
        "        threshold (float): Threshold for measuring the new optimum,\n",
        "            to only focus on significant changes. Default: 1e-4.\n",
        "        threshold_mode (str): One of `rel`, `abs`. In `rel` mode,\n",
        "            dynamic_threshold = best * ( 1 + threshold ) in 'max'\n",
        "            mode or best * ( 1 - threshold ) in `min` mode.\n",
        "            In `abs` mode, dynamic_threshold = best + threshold in\n",
        "            `max` mode or best - threshold in `min` mode. Default: 'rel'.\n",
        "        cooldown (int): Number of epochs to wait before resuming\n",
        "            normal operation after lr has been reduced. Default: 0.\n",
        "        min_lr (float or list): A scalar or a list of scalars. A\n",
        "            lower bound on the learning rate of all param groups\n",
        "            or each group respectively. Default: 0.\n",
        "        eps (float): Minimal decay applied to lr. If the difference\n",
        "            between new and old lr is smaller than eps, the update is\n",
        "            ignored. Default: 1e-8.\n",
        "    Example:\n",
        "        >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "        >>> scheduler = torch.optim.ReduceLROnPlateau(optimizer, 'min')\n",
        "        >>> for epoch in range(10):\n",
        "        >>>     train(...)\n",
        "        >>>     val_loss = validate(...)\n",
        "        >>>     # Note that step should be called after validate()\n",
        "        >>>     scheduler.step(val_loss)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, mode='min', factor=0.1, patience=10,\n",
        "                 verbose=False, threshold=1e-4, threshold_mode='rel',\n",
        "                 cooldown=0, min_lr=0, eps=1e-8):\n",
        "\n",
        "        if factor >= 1.0:\n",
        "            raise ValueError('Factor should be < 1.0.')\n",
        "        self.factor = factor\n",
        "\n",
        "        if not isinstance(optimizer, Optimizer):\n",
        "            raise TypeError('{} is not an Optimizer'.format(\n",
        "                type(optimizer).__name__))\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        if isinstance(min_lr, list) or isinstance(min_lr, tuple):\n",
        "            if len(min_lr) != len(optimizer.param_groups):\n",
        "                raise ValueError(\"expected {} min_lrs, got {}\".format(\n",
        "                    len(optimizer.param_groups), len(min_lr)))\n",
        "            self.min_lrs = list(min_lr)\n",
        "        else:\n",
        "            self.min_lrs = [min_lr] * len(optimizer.param_groups)\n",
        "\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.cooldown = cooldown\n",
        "        self.cooldown_counter = 0\n",
        "        self.mode = mode\n",
        "        self.threshold = threshold\n",
        "        self.threshold_mode = threshold_mode\n",
        "        self.best = None\n",
        "        self.num_bad_epochs = None\n",
        "        self.mode_worse = None  # the worse value for the chosen mode\n",
        "        self.is_better = None\n",
        "        self.eps = eps\n",
        "        self.last_epoch = -1\n",
        "        self._init_is_better(mode=mode, threshold=threshold,\n",
        "                             threshold_mode=threshold_mode)\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self):\n",
        "        \"\"\"Resets num_bad_epochs counter and cooldown counter.\"\"\"\n",
        "        self.best = self.mode_worse\n",
        "        self.cooldown_counter = 0\n",
        "        self.num_bad_epochs = 0\n",
        "\n",
        "    def step(self, metrics, epoch=None):\n",
        "        current = metrics\n",
        "        if epoch is None:\n",
        "            epoch = self.last_epoch = self.last_epoch + 1\n",
        "        self.last_epoch = epoch\n",
        "\n",
        "        if self.is_better(current, self.best):\n",
        "            self.best = current\n",
        "            self.num_bad_epochs = 0\n",
        "        else:\n",
        "            self.num_bad_epochs += 1\n",
        "\n",
        "        if self.in_cooldown:\n",
        "            self.cooldown_counter -= 1\n",
        "            self.num_bad_epochs = 0  # ignore any bad epochs in cooldown\n",
        "\n",
        "        if self.num_bad_epochs > self.patience:\n",
        "            self._reduce_lr(epoch)\n",
        "            self.cooldown_counter = self.cooldown\n",
        "            self.num_bad_epochs = 0\n",
        "\n",
        "    def _reduce_lr(self, epoch):\n",
        "        for i, param_group in enumerate(self.optimizer.param_groups):\n",
        "            old_lr = float(param_group['lr'])\n",
        "            new_lr = max(old_lr * self.factor, self.min_lrs[i])\n",
        "            if old_lr - new_lr > self.eps:\n",
        "                param_group['lr'] = new_lr\n",
        "                if self.verbose:\n",
        "                    print('Epoch {:5d}: reducing learning rate'\n",
        "                          ' of group {} to {:.4e}.'.format(epoch, i, new_lr))\n",
        "\n",
        "    @property\n",
        "    def in_cooldown(self):\n",
        "        return self.cooldown_counter > 0\n",
        "\n",
        "    def _init_is_better(self, mode, threshold, threshold_mode):\n",
        "        if mode not in {'min', 'max'}:\n",
        "            raise ValueError('mode ' + mode + ' is unknown!')\n",
        "        if threshold_mode not in {'rel', 'abs'}:\n",
        "            raise ValueError('threshold mode ' + mode + ' is unknown!')\n",
        "        if mode == 'min' and threshold_mode == 'rel':\n",
        "            rel_epsilon = 1. - threshold\n",
        "            self.is_better = lambda a, best: a < best * rel_epsilon\n",
        "            self.mode_worse = float('Inf')\n",
        "        elif mode == 'min' and threshold_mode == 'abs':\n",
        "            self.is_better = lambda a, best: a < best - threshold\n",
        "            self.mode_worse = float('Inf')\n",
        "        elif mode == 'max' and threshold_mode == 'rel':\n",
        "            rel_epsilon = threshold + 1.\n",
        "            self.is_better = lambda a, best: a > best * rel_epsilon\n",
        "            self.mode_worse = -float('Inf')\n",
        "        else:  # mode == 'max' and epsilon_mode == 'abs':\n",
        "            self.is_better = lambda a, best: a > best + threshold\n",
        "            self.mode_worse = -float('Inf')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsx9zt5U_UF2"
      },
      "source": [
        "import torch\n",
        "from torch import optim\n",
        "from torch import  nn\n",
        "from collections import OrderedDict\n",
        "from utils import make_hyparam_string, save_new_pickle, read_pickle, SavePloat_Voxels, generateZ\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "def train():\n",
        "\n",
        "    hyparam_list = [(\"model\", 'abc'),\n",
        "                    (\"cube\", 512),\n",
        "                    (\"bs\", 1),\n",
        "                    (\"g_lr\", 1e-4),\n",
        "                    (\"d_lr\", 1e-4),]\n",
        "\n",
        "    hyparam_dict = OrderedDict(((arg, value) for arg, value in hyparam_list))\n",
        "    log_param = make_hyparam_string(hyparam_dict)\n",
        "    print(log_param)\n",
        "\n",
        "\n",
        "    # datset define\n",
        "    dsets = ShapeNetDataset()\n",
        "    dset_loaders = torch.utils.data.DataLoader(dsets, batch_size=1, shuffle=True, num_workers=1)\n",
        "\n",
        "    # model define\n",
        "    D = _D()\n",
        "    G = _G()\n",
        "\n",
        "    D_solver = optim.Adam(D.parameters(), lr=1e-4)\n",
        "    G_solver = optim.Adam(G.parameters(), lr=1e-4)\n",
        "\n",
        "    D_scheduler = MultiStepLR(D_solver, milestones=[500, 1000])\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"using cuda\")\n",
        "        D.cuda()\n",
        "        G.cuda()\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    for epoch in range(50):\n",
        "        for i, X in enumerate(dset_loaders):\n",
        "\n",
        "            X = var_or_cuda(X)\n",
        "\n",
        "            if X.size()[0] != int(1):\n",
        "                #print(\"batch_size != {} drop last incompatible batch\".format(int(args.batch_size)))\n",
        "                continue\n",
        "\n",
        "            Z = generateZ()\n",
        "            real_labels = var_or_cuda(torch.ones(1))\n",
        "            fake_labels = var_or_cuda(torch.zeros(1))\n",
        "\n",
        "\n",
        "            # ============= Train the discriminator =============#\n",
        "            d_real = D(X)\n",
        "            d_real_loss = criterion(d_real, real_labels)\n",
        "\n",
        "\n",
        "            fake = G(Z)\n",
        "            d_fake = D(fake)\n",
        "            d_fake_loss = criterion(d_fake, fake_labels)\n",
        "\n",
        "            d_loss = d_real_loss + d_fake_loss\n",
        "\n",
        "\n",
        "            d_real_acu = torch.ge(d_real.squeeze(), 0.5).float()\n",
        "            d_fake_acu = torch.le(d_fake.squeeze(), 0.5).float()\n",
        "            d_total_acu = torch.mean(torch.cat((d_real_acu, d_fake_acu),0))\n",
        "\n",
        "            if d_total_acu <=10:\n",
        "                D.zero_grad()\n",
        "                d_loss.backward()\n",
        "                D_solver.step()\n",
        "\n",
        "            # =============== Train the generator ===============#\n",
        "\n",
        "            Z = generateZ()\n",
        "\n",
        "            fake = G(Z)\n",
        "            d_fake = D(fake)\n",
        "            g_loss = criterion(d_fake, real_labels)\n",
        "\n",
        "            D.zero_grad()\n",
        "            G.zero_grad()\n",
        "            g_loss.backward()\n",
        "            G_solver.step()\n",
        "\n",
        "        # =============== logging each iteration ===============#\n",
        "        iteration = str(G_solver.state_dict()['state'][G_solver.state_dict()['param_groups'][0]['params'][0]]['step'])\n",
        "        \n",
        "        # =============== each epoch save model or save image ===============#\n",
        "        print('Iter-{}; , D_loss : {:.4}, G_loss : {:.4}, D_acu : {:.4}, D_lr : {:.4}'.format(iteration, d_loss.data[0], g_loss.data[0], d_total_acu.data[0], D_solver.state_dict()['param_groups'][0][\"lr\"]))\n",
        "\n",
        "\n",
        "\n",
        "        D_scheduler.step()\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "k8tDcJlRJQQJ",
        "outputId": "4bdaf64b-f489-45f3-b122-b6a879e4c431"
      },
      "source": [
        "    hyparam_list = [(\"model\", 'abc'),\n",
        "                    (\"cube\", 512),\n",
        "                    (\"bs\", 1),\n",
        "                    (\"g_lr\", 1e-4),\n",
        "                    (\"d_lr\", 1e-4),]\n",
        "\n",
        "    hyparam_dict = OrderedDict(((arg, value) for arg, value in hyparam_list))\n",
        "    log_param = make_hyparam_string(hyparam_dict)\n",
        "    print(log_param)\n",
        "\n",
        "\n",
        "    # datset define\n",
        "    dsets = ShapeNetDataset()\n",
        "    dset_loaders = torch.utils.data.DataLoader(dsets, batch_size=1, shuffle=True, num_workers=1)\n",
        "\n",
        "    # model define\n",
        "    D = _D()\n",
        "    G = _G()\n",
        "\n",
        "    D_solver = optim.Adam(D.parameters(), lr=1e-4)\n",
        "    G_solver = optim.Adam(G.parameters(), lr=1e-4)\n",
        "\n",
        "    D_scheduler = MultiStepLR(D_solver, milestones=[500, 1000])\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"using cuda\")\n",
        "        D.cuda()\n",
        "        G.cuda()\n",
        "\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    for epoch in range(50):\n",
        "        for i, X in enumerate(dset_loaders):\n",
        "\n",
        "            X = var_or_cuda(X)\n",
        "\n",
        "            if X.size()[0] != int(1):\n",
        "                #print(\"batch_size != {} drop last incompatible batch\".format(int(args.batch_size)))\n",
        "                continue\n",
        "\n",
        "            Z = generateZ()\n",
        "            real_labels = var_or_cuda(torch.ones(1))\n",
        "            fake_labels = var_or_cuda(torch.zeros(1))\n",
        "\n",
        "\n",
        "            # ============= Train the discriminator =============#\n",
        "            d_real = D(X)\n",
        "            d_real_loss = criterion(d_real, real_labels)\n",
        "\n",
        "\n",
        "            fake = G(Z)\n",
        "            d_fake = D(fake)\n",
        "            d_fake_loss = criterion(d_fake, fake_labels)\n",
        "\n",
        "            d_loss = d_real_loss + d_fake_loss\n",
        "\n",
        "\n",
        "            d_real_acu = torch.ge(d_real.squeeze(), 0.5).float()\n",
        "            d_fake_acu = torch.le(d_fake.squeeze(), 0.5).float()\n",
        "            d_total_acu = torch.mean(torch.cat((d_real_acu, d_fake_acu),0))\n",
        "\n",
        "            if d_total_acu <=10:\n",
        "                D.zero_grad()\n",
        "                d_loss.backward()\n",
        "                D_solver.step()\n",
        "\n",
        "            # =============== Train the generator ===============#\n",
        "\n",
        "            Z = generateZ()\n",
        "\n",
        "            fake = G(Z)\n",
        "            d_fake = D(fake)\n",
        "            g_loss = criterion(d_fake, real_labels)\n",
        "\n",
        "            D.zero_grad()\n",
        "            G.zero_grad()\n",
        "            g_loss.backward()\n",
        "            G_solver.step()\n",
        "\n",
        "        # =============== logging each iteration ===============#\n",
        "        iteration = str(G_solver.state_dict()['state'][G_solver.state_dict()['param_groups'][0]['params'][0]]['step'])\n",
        "        \n",
        "        # =============== each epoch save model or save image ===============#\n",
        "        print('Iter-{}; , D_loss : {:.4}, G_loss : {:.4}, D_acu : {:.4}, D_lr : {:.4}'.format(iteration, d_loss.data[0], g_loss.data[0], d_total_acu.data[0], D_solver.state_dict()['param_groups'][0][\"lr\"]))\n",
        "\n",
        "\n",
        "\n",
        "        D_scheduler.step()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model=abc_cube=512_bs=1_g_lr=0.0001_d_lr=0.0001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-21f7ca3e61d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# ============= Train the discriminator =============#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0md_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0md_real_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-b5919a183a54>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;31m#print(out.size()) # torch.Size([100, 1, 64, 64, 64])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 1, 512, 512, 512]' is invalid for input of size 271056896"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZEVsG-vSxG6",
        "outputId": "262d4797-f3a8-42ad-9433-cdff7dbc459b"
      },
      "source": [
        "fake.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 64, 64, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "rturzO5wTacs",
        "outputId": "fe3be18c-d739-42f1-db6d-0334ac77429f"
      },
      "source": [
        "            fake = G(Z)\n",
        "            d_fake = D(fake)\n",
        "            d_fake_loss = criterion(d_fake, fake_labels)\n",
        "\n",
        "            d_loss = d_real_loss + d_fake_loss\n",
        "\n",
        "\n",
        "            d_real_acu = torch.ge(d_real.squeeze(), 0.5).float()\n",
        "            d_fake_acu = torch.le(d_fake.squeeze(), 0.5).float()\n",
        "            d_total_acu = torch.mean(torch.cat((d_real_acu, d_fake_acu),0))\n",
        "\n",
        "            if d_total_acu <=10:\n",
        "                D.zero_grad()\n",
        "                d_loss.backward()\n",
        "                D_solver.step()\n",
        "\n",
        "            # =============== Train the generator ===============#\n",
        "\n",
        "            Z = generateZ()\n",
        "\n",
        "            fake = G(Z)\n",
        "            d_fake = D(fake)\n",
        "            g_loss = criterion(d_fake, real_labels)\n",
        "\n",
        "            D.zero_grad()\n",
        "            G.zero_grad()\n",
        "            g_loss.backward()\n",
        "            G_solver.step()\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-714f9148b1aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0md_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0md_fake_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_real_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md_fake_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-b5919a183a54>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;31m#print(out.size()) # torch.Size([100, 1, 64, 64, 64])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 1, 512, 512, 512]' is invalid for input of size 262144"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WYqYqg0TfpW"
      },
      "source": [
        "\n",
        "        # =============== logging each iteration ===============#\n",
        "        iteration = str(G_solver.state_dict()['state'][G_solver.state_dict()['param_groups'][0]['params'][0]]['step'])\n",
        "        \n",
        "        # =============== each epoch save model or save image ===============#\n",
        "        print('Iter-{}; , D_loss : {:.4}, G_loss : {:.4}, D_acu : {:.4}, D_lr : {:.4}'.format(iteration, d_loss.data[0], g_loss.data[0], d_total_acu.data[0], D_solver.state_dict()['param_groups'][0][\"lr\"]))\n",
        "\n",
        "\n",
        "\n",
        "        D_scheduler.step()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}