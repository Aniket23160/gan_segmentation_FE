{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "error.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPLgz66P3eN9mnDG0idM8ni",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greyhound101/gan_segmentation_FE/blob/main/error.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkihMbsoz1hZ",
        "outputId": "cda6f09e-2d7a-4250-b2eb-36e8a55751de"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG2pnjJY0ORv"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/gdrive/My Drive/segmentation/Training_Batch1.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhMRVutR0OOe"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "for i in range(5,28):\n",
        "    os.remove( '/content/media/nas/01_Datasets/CT/LITS/Training Batch 1/segmentation-'+str(i)+'.nii')\n",
        "    os.remove( '/content/media/nas/01_Datasets/CT/LITS/Training Batch 1/volume-'+str(i)+'.nii')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJMLGdoI0Ybc",
        "outputId": "bf75cc9b-a193-45b4-9c2f-0eb2cd1cecd7"
      },
      "source": [
        "pip install medpy"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting medpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/70/c1fd5dd60242eee81774696ea7ba4caafac2bad8f028bba94b1af83777d7/MedPy-0.4.0.tar.gz (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from medpy) (1.19.5)\n",
            "Collecting SimpleITK>=1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/6b/85df5eb3a8059b23a53a9f224476e75473f9bcc0a8583ed1a9c34619f372/SimpleITK-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (47.4MB)\n",
            "\u001b[K     |████████████████████████████████| 47.4MB 61kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: medpy\n",
            "  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for medpy: filename=MedPy-0.4.0-cp37-cp37m-linux_x86_64.whl size=754479 sha256=0ac06bad1f6d6aed4eeac5107512be30f2df3d9afb93c73c36342f148c9facfa\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/c9/9c/2c6281c7a72b9fb1570862a4f028af7ce38405008354fbf870\n",
            "Successfully built medpy\n",
            "Installing collected packages: SimpleITK, medpy\n",
            "Successfully installed SimpleITK-2.0.2 medpy-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRzJyZ270YYk",
        "outputId": "d7ec85fa-2f12-47ec-8c84-9dd5274a0d2e"
      },
      "source": [
        "from medpy.io import load, save\n",
        "import os\n",
        "import os.path\n",
        "import gc\n",
        "from scipy.ndimage import zoom\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "try:\n",
        "  os.mkdir('data')\n",
        "except:\n",
        "  pass\n",
        "for file in tqdm(range(5)):\n",
        "        shape=4/2\n",
        "        img, img_header = load('/content/media/nas/01_Datasets/CT/LITS/Training Batch 1/volume-'+str(file)+'.nii')\n",
        "        seg, img_header = load('/content/media/nas/01_Datasets/CT/LITS/Training Batch 1/segmentation-'+str(file)+'.nii')\n",
        "        arr=np.where(seg==2)[-1]\n",
        "        mn=(arr.min()+arr.max())/2\n",
        "        \n",
        "        \n",
        "        if mn-shape<0:\n",
        "          start=0\n",
        "          end=shape*2\n",
        "        elif mn+shape>img.shape[-1]:\n",
        "          end=img.shape[-1]\n",
        "          start=end-shape*2\n",
        "        else:\n",
        "          start=int(max(0,(mn-shape)))\n",
        "          end=int(min(img.shape[-1],int(mn+shape)))\n",
        "        \n",
        "        \n",
        "        img=img[:,:,start:end]\n",
        "        img[img < -200] = -200\n",
        "        img[img > 250] = 250\n",
        "        img+=112\n",
        "        img/=117\n",
        "        img = np.array(img, dtype='float32')\n",
        "        img = zoom(img, (0.125, 0.125, 1))\n",
        "        # print (\"Saving image \"+str(file))\n",
        "        # np.save( \"/content/data/volume-\" + str(file) ,zoom(img, (0.125, 0.125, 1)))\n",
        "        # print(img.shape)\n",
        "        # del([img])\n",
        "        # gc.collect()\n",
        "        seg=seg.astype('float64')\n",
        "        seg+=0.1645\n",
        "        seg/=0.023138\n",
        "        seg = np.array(seg, dtype='float32')\n",
        "        seg=seg[:,:,start:end]\n",
        "        # print (\"Saving image \"+file)\n",
        "        seg=zoom(seg, (0.125, 0.125, 1))\n",
        "        total=np.concatenate([img,seg],-1)\n",
        "        print(total.shape)\n",
        "        np.save( \"/content/data/total-\" + str(file),total)\n",
        "        del([seg,img,total])\n",
        "        gc.collect()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 1/5 [00:00<00:02,  1.68it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 64, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 2/5 [00:04<00:04,  1.45s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 64, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 3/5 [00:19<00:11,  5.66s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 64, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 4/5 [00:33<00:08,  8.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 64, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [01:03<00:00, 12.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(64, 64, 8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM4ue4GQzBBd",
        "outputId": "2e207c89-51fb-4a60-9d9d-463a23431b56"
      },
      "source": [
        "%%writefile ATLAS_dataset.py\n",
        "import csv\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import os\n",
        "from torchvision import transforms\n",
        "from skimage.transform import resize\n",
        "import nibabel as nib\n",
        "from skimage import exposure\n",
        "\n",
        "class ATLASdataset(Dataset):\n",
        "    def __init__(self,augmentation=True):\n",
        "        list_path = []\n",
        "        for i in range(9):\n",
        "            root = '../ATLAS_R1.1/Site'+str(i+1)\n",
        "        \n",
        "            list_img = os.listdir(root)\n",
        "            for s in range(len(list_img)):\n",
        "                list_path.append(os.path.join(root,list_img[s]))\n",
        "\n",
        "        list_path.sort()\n",
        "        self.augmentation= augmentation\n",
        "        self.imglist = list_path\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.imglist)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = os.path.join(self.imglist[index],'t01')\n",
        "        tempimg = nib.load(os.path.join(path,'T1w_p.nii'))\n",
        "        B = np.flip(tempimg.get_data(),1)\n",
        "        sp_size = 64\n",
        "        img = resize(B, (sp_size,sp_size,sp_size), mode='constant')\n",
        "        img = 1.0*img\n",
        "        img = (img-np.min(img))/(np.max(img)-np.min(img))\n",
        "\n",
        "        if self.augmentation:\n",
        "            random_n = torch.rand(1)\n",
        "            if random_n[0] > 0.5:\n",
        "                img = np.flip(img,0)\n",
        "                \n",
        "        img = np.ascontiguousarray(img,dtype=np.float32)\n",
        "\n",
        "        imageout = torch.from_numpy(img).float().view(1,sp_size,sp_size,sp_size)\n",
        "        imageout = 2*imageout-1\n",
        "\n",
        "        return imageout "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting ATLAS_dataset.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOUBCCNDy5qU",
        "outputId": "dd8ec52c-6edb-4466-e4ac-e3d0b661d90a"
      },
      "source": [
        "%%writefile BRATS_dataset.py\n",
        "import csv\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import os\n",
        "from skimage.transform import resize\n",
        "from nilearn import surface\n",
        "import nibabel as nib\n",
        "from skimage import exposure\n",
        "\n",
        "class BRATSdataset(Dataset):\n",
        "    def __init__(self, train=True, imgtype = 'flair', severity='HGG',is_flip=False,augmentation=True):\n",
        "        self.augmentation = augmentation\n",
        "        if train:\n",
        "            self.root = '../Training_brats/' + severity\n",
        "        else:\n",
        "            self.root = '../Validation_brats'\n",
        "        self.imgtype = imgtype\n",
        "        list_img = os.listdir(self.root)\n",
        "        list_img.sort()\n",
        "        self.imglist = list_img\n",
        "        self.is_flip = is_flip\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.imglist)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        path = os.path.join(self.root,self.imglist[index])\n",
        "        \n",
        "        img = nib.load(os.path.join(path,self.imglist[index]+'_'+self.imgtype+'.nii.gz'))\n",
        "        gt = nib.load(os.path.join(path,self.imglist[index])+'_'+'seg.nii.gz')\n",
        "\n",
        "        A = np.zeros((240,240,166))\n",
        "        G = np.zeros((240,240,166))\n",
        "        A[:,:,11:] = img.get_data()\n",
        "        G[:,:,11:] = gt.get_data()\n",
        "        x=[]\n",
        "        y=[]\n",
        "        z=[]\n",
        "        \n",
        "        for i in range(240):\n",
        "            if np.all(A[i,:,:] ==0):\n",
        "                x.append(i)\n",
        "            if np.all(A[:,i,:]==0):\n",
        "                y.append(i)\n",
        "            if i <155:\n",
        "                if np.all(A[:,:,i]==0):\n",
        "                    z.append(i)\n",
        "\n",
        "        xl,yl,zl = 0,0,0\n",
        "        xh,yh,zh = 240,240,155\n",
        "        for xn in x:\n",
        "            if xn < 120:\n",
        "                if xn> xl:\n",
        "                    xl = xn\n",
        "            else:\n",
        "                if xn<xh:\n",
        "                    xh = xn\n",
        "        for yn in y:\n",
        "            if yn < 120:\n",
        "                if yn> yl:\n",
        "                    yl = yn\n",
        "            else:\n",
        "                if yn<yh:\n",
        "                    yh = yn\n",
        "        for zn in z:\n",
        "            if zn < 77:\n",
        "                if zn> zl:\n",
        "                    zl = zn\n",
        "            else:\n",
        "                if zn<zh:\n",
        "                    zh = zn\n",
        "\n",
        "        B = A[xl-10:xh+10,yl-10:yh+10,zl-10:zh+10]\n",
        "        B = resize(B, (128, 128, 128), mode='constant')\n",
        "        \n",
        "        if self.is_flip:\n",
        "            B = np.swapaxes(B,1,2)\n",
        "            B = np.flip(B,1)\n",
        "            B =np.flip(B,2)\n",
        "        \n",
        "        sp_size = 64\n",
        "        img = resize(B, (sp_size,sp_size,sp_size), mode='constant')\n",
        "        if self.augmentation:\n",
        "            random_n = torch.rand(1)\n",
        "            random_i = 0.3*torch.rand(1)[0]+0.7\n",
        "            if random_n[0] > 0.5:\n",
        "                img = np.flip(img,0)\n",
        "\n",
        "        img = 1.0*img\n",
        "        img = exposure.rescale_intensity(img)\n",
        "        img = (img-np.min(img))/(np.max(img)-np.min(img))\n",
        "        img = 2*img-1\n",
        "\n",
        "        imageout = torch.from_numpy(img).float().view(1,sp_size,sp_size,sp_size)\n",
        "\n",
        "        return imageout"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting BRATS_dataset.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmUcIoPe95T6",
        "outputId": "d9c4fc56-ea52-43d0-b7a7-81aa0ba04ac1"
      },
      "source": [
        "pip install nilearn"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nilearn in /usr/local/lib/python3.7/dist-packages (0.7.1)\n",
            "Requirement already satisfied: nibabel>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from nilearn) (3.0.2)\n",
            "Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.1.5)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.7/dist-packages (from nilearn) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.19 in /usr/local/lib/python3.7/dist-packages (from nilearn) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->nilearn) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->nilearn) (2018.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (3.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.18.0->nilearn) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0cF752Iywks"
      },
      "source": [
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import os\n",
        "from torchvision import transforms\n",
        "from skimage.transform import resize\n",
        "from nilearn import surface\n",
        "from medpy.io import *\n",
        "import glob\n",
        "class ADNIdataset(Dataset):\n",
        "\tdef __init__(self, augmentation=False):\n",
        "\t\tself.augmentation = augmentation\n",
        "\t\tself.name = []\n",
        "\t\tfor data in glob.glob('/content/data/total-*.npy'):\n",
        "\t\t\tself.name.append(data)\n",
        "\t\tself.name = np.asarray(self.name)\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.name)\n",
        "\n",
        "\tdef __getitem__(self, index):\n",
        "\t\tpath = self.name[index]\n",
        "\t\timg = np.load(path)\n",
        "\n",
        "\t\timg = np.flip(img,1)\n",
        "\t\timg = np.flip(img,2)\n",
        "\t\tsp_size = 64\n",
        "\t\timg = resize(img, (sp_size,sp_size,sp_size), mode='constant')\n",
        "\t\tif self.augmentation:\n",
        "\t\t\trandom_n = torch.rand(1)\n",
        "\t\t\trandom_i = 0.3*torch.rand(1)[0]+0.7\n",
        "\t\t\tif random_n[0] > 0.5:\n",
        "\t\t\t\timg = np.flip(img,0)\n",
        "                \n",
        "\t\t\timg = img*random_i.data.cpu().numpy()\n",
        "            \n",
        "\t\timageout = torch.from_numpy(img).float().view(1,sp_size,sp_size,sp_size)\n",
        "\t\timageout = imageout*2-1\n",
        "\n",
        "\t\treturn imageout"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_QADNv8zHbS",
        "outputId": "5fb2a735-587d-40bf-edef-a0a716bbaf93"
      },
      "source": [
        "%%writefile Model_alphaWGAN.py\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "\n",
        "#***********************************************\n",
        "#Encoder and Discriminator has same architecture\n",
        "#***********************************************\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, channel=512,out_class=1,is_dis =True):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.is_dis=is_dis\n",
        "        self.channel = channel\n",
        "        n_class = out_class \n",
        "        \n",
        "        self.conv1 = nn.Conv3d(1, channel//8, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv3d(channel//8, channel//4, kernel_size=4, stride=2, padding=1)\n",
        "        self.bn2 = nn.BatchNorm3d(channel//4)\n",
        "        self.conv3 = nn.Conv3d(channel//4, channel//2, kernel_size=4, stride=2, padding=1)\n",
        "        self.bn3 = nn.BatchNorm3d(channel//2)\n",
        "        self.conv4 = nn.Conv3d(channel//2, channel, kernel_size=4, stride=2, padding=1)\n",
        "        self.bn4 = nn.BatchNorm3d(channel)\n",
        "        self.conv5 = nn.Conv3d(channel, n_class, kernel_size=4, stride=1, padding=0)\n",
        "        \n",
        "    def forward(self, x, _return_activations=False):\n",
        "        h1 = F.leaky_relu(self.conv1(x), negative_slope=0.2)\n",
        "        h2 = F.leaky_relu(self.bn2(self.conv2(h1)), negative_slope=0.2)\n",
        "        h3 = F.leaky_relu(self.bn3(self.conv3(h2)), negative_slope=0.2)\n",
        "        h4 = F.leaky_relu(self.bn4(self.conv4(h3)), negative_slope=0.2)\n",
        "        h5 = self.conv5(h4)\n",
        "        output = h5\n",
        "        \n",
        "        return output\n",
        "    \n",
        "class Code_Discriminator(nn.Module):\n",
        "    def __init__(self, code_size=100,num_units=750):\n",
        "        super(Code_Discriminator, self).__init__()\n",
        "        n_class = 1\n",
        "        self.l1 = nn.Sequential(nn.Linear(code_size, num_units),\n",
        "                                nn.BatchNorm1d(num_units),\n",
        "                                nn.LeakyReLU(0.2,inplace=True))\n",
        "        self.l2 = nn.Sequential(nn.Linear(num_units, num_units),\n",
        "                                nn.BatchNorm1d(num_units),\n",
        "                                nn.LeakyReLU(0.2,inplace=True))\n",
        "        self.l3 = nn.Linear(num_units, 1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        h1 = self.l1(x)\n",
        "        h2 = self.l2(h1)\n",
        "        h3 = self.l3(h2)\n",
        "        output = h3\n",
        "            \n",
        "        return output\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise:int=100, channel:int=64):\n",
        "        super(Generator, self).__init__()\n",
        "        _c = channel\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.noise = noise\n",
        "        self.tp_conv1 = nn.ConvTranspose3d(noise, _c*8, kernel_size=4, stride=1, padding=0, bias=False)\n",
        "        self.bn1 = nn.BatchNorm3d(_c*8)\n",
        "        \n",
        "        self.tp_conv2 = nn.Conv3d(_c*8, _c*4, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm3d(_c*4)\n",
        "        \n",
        "        self.tp_conv3 = nn.Conv3d(_c*4, _c*2, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm3d(_c*2)\n",
        "        \n",
        "        self.tp_conv4 = nn.Conv3d(_c*2, _c, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn4 = nn.BatchNorm3d(_c)\n",
        "        \n",
        "        self.tp_conv5 = nn.Conv3d(_c, 1, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        \n",
        "    def forward(self, noise):\n",
        "\n",
        "        noise = noise.view(-1,self.noise,1,1,1)\n",
        "        h = self.tp_conv1(noise)\n",
        "        h = self.relu(self.bn1(h))\n",
        "        \n",
        "        h = F.upsample(h,scale_factor = 2)\n",
        "        h = self.tp_conv2(h)\n",
        "        h = self.relu(self.bn2(h))\n",
        "     \n",
        "        h = F.upsample(h,scale_factor = 2)\n",
        "        h = self.tp_conv3(h)\n",
        "        h = self.relu(self.bn3(h))\n",
        "\n",
        "        h = F.upsample(h,scale_factor = 2)\n",
        "        h = self.tp_conv4(h)\n",
        "        h = self.relu(self.bn4(h))\n",
        "\n",
        "        h = F.upsample(h,scale_factor = 2)\n",
        "        h = self.tp_conv5(h)\n",
        "\n",
        "        h = F.tanh(h)\n",
        "\n",
        "        return h"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting Model_alphaWGAN.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viwzmKOwypBn",
        "outputId": "be8b3e6b-feef-4f6a-d1e2-f771de1cd494"
      },
      "source": [
        "%pylab inline\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "from torch import autograd\n",
        "from torch.autograd import Variable\n",
        "import nibabel as nib\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import dataloader\n",
        "from nilearn import plotting\n",
        "# from ADNI_dataset import *\n",
        "from BRATS_dataset import *\n",
        "from ATLAS_dataset import *\n",
        "from Model_alphaWGAN import *\n",
        "\n",
        "\n",
        "BATCH_SIZE=4\n",
        "gpu = True\n",
        "workers = 4\n",
        "\n",
        "LAMBDA= 10\n",
        "_eps = 1e-15\n",
        "Use_BRATS=False\n",
        "Use_ATLAS = False\n",
        "\n",
        "#setting latent variable sizes\n",
        "latent_dim = 1000\n",
        "\n",
        "\n",
        "trainset = ADNIdataset(augmentation=True)\n",
        "train_loader = torch.utils.data.DataLoader(trainset,batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True,num_workers=workers)\n",
        "\n",
        "\n",
        "def inf_train_gen(data_loader):\n",
        "    while True:\n",
        "        for _,images in enumerate(data_loader):\n",
        "            yield images\n",
        "\n",
        "\n",
        "G = Generator(noise = latent_dim)\n",
        "CD = Code_Discriminator(code_size = latent_dim ,num_units = 4096)\n",
        "D = Discriminator(is_dis=True)\n",
        "E = Discriminator(out_class = latent_dim,is_dis=False)\n",
        "\n",
        "G.cuda()\n",
        "D.cuda()\n",
        "CD.cuda()\n",
        "E.cuda()\n",
        "\n",
        "\n",
        "g_optimizer = optim.Adam(G.parameters(), lr=0.0002)\n",
        "d_optimizer = optim.Adam(D.parameters(), lr=0.0002)\n",
        "e_optimizer = optim.Adam(E.parameters(), lr = 0.0002)\n",
        "cd_optimizer = optim.Adam(CD.parameters(), lr = 0.0002)\n",
        "\n",
        "\n",
        "def calc_gradient_penalty(model, x, x_gen, w=10):\n",
        "    \"\"\"WGAN-GP gradient penalty\"\"\"\n",
        "    assert x.size()==x_gen.size(), \"real and sampled sizes do not match\"\n",
        "    alpha_size = tuple((len(x), *(1,)*(x.dim()-1)))\n",
        "    alpha_t = torch.cuda.FloatTensor if x.is_cuda else torch.Tensor\n",
        "    alpha = alpha_t(*alpha_size).uniform_()\n",
        "    x_hat = x.data*alpha + x_gen.data*(1-alpha)\n",
        "    x_hat = Variable(x_hat, requires_grad=True)\n",
        "\n",
        "    def eps_norm(x):\n",
        "        x = x.view(len(x), -1)\n",
        "        return (x*x+_eps).sum(-1).sqrt()\n",
        "    def bi_penalty(x):\n",
        "        return (x-1)**2\n",
        "    grad_xhat = torch.autograd.grad(model(x_hat).sum(), x_hat, create_graph=True, only_inputs=True)[0]\n",
        "\n",
        "    penalty = w*bi_penalty(eps_norm(grad_xhat)).mean()\n",
        "    return penalty\n",
        "\n",
        "\n",
        "real_y = Variable(torch.ones((BATCH_SIZE, 1)).cuda())\n",
        "fake_y = Variable(torch.zeros((BATCH_SIZE, 1)).cuda())\n",
        "\n",
        "criterion_bce = nn.BCELoss()\n",
        "criterion_l1 = nn.L1Loss()\n",
        "criterion_mse = nn.MSELoss()\n",
        "\n",
        "\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['Generator', 'plotting', 'resize']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "HT-xdxCwBXU2",
        "outputId": "6b017831-c3c0-4445-dab1-85b773c92e23"
      },
      "source": [
        "g_iter = 1\n",
        "d_iter = 1\n",
        "cd_iter =1\n",
        "TOTAL_ITER = 200000\n",
        "gen_load = inf_train_gen(train_loader)\n",
        "for iteration in range(TOTAL_ITER):\n",
        "    for p in D.parameters():  \n",
        "        p.requires_grad = False\n",
        "    for p in CD.parameters():  \n",
        "        p.requires_grad = False\n",
        "    for p in E.parameters():  \n",
        "        p.requires_grad = True\n",
        "    for p in G.parameters():  \n",
        "        p.requires_grad = True\n",
        "\n",
        "    ###############################################\n",
        "    # Train Encoder - Generator \n",
        "    ###############################################\n",
        "    for iters in range(g_iter):\n",
        "        G.zero_grad()\n",
        "        E.zero_grad()\n",
        "        real_images = gen_load.__next__()\n",
        "        if real_images.shape[0]==1:\n",
        "          real_images = gen_load.__next__() \n",
        "        print(real_images.shape) \n",
        "        _batch_size = real_images.size(0)\n",
        "        real_images = Variable(real_images,volatile=True).cuda()\n",
        "        z_rand = Variable(torch.randn((_batch_size,latent_dim)),volatile=True).cuda()\n",
        "        z_hat = E(real_images).view(_batch_size,-1)\n",
        "        x_hat = G(z_hat)\n",
        "        x_rand = G(z_rand)\n",
        "        c_loss = -CD(z_hat).mean()\n",
        "\n",
        "        d_real_loss = D(x_hat).mean()\n",
        "        d_fake_loss = D(x_rand).mean()\n",
        "        d_loss = -d_fake_loss-d_real_loss\n",
        "        l1_loss =10* criterion_l1(x_hat,real_images)\n",
        "        loss1 = l1_loss + c_loss + d_loss\n",
        "\n",
        "        if iters<g_iter-1:\n",
        "            loss1.backward()\n",
        "        else:\n",
        "            loss1.backward(retain_graph=True)\n",
        "        e_optimizer.step()\n",
        "        g_optimizer.step()\n",
        "        g_optimizer.step()\n",
        "\n",
        "\n",
        "    ###############################################\n",
        "    # Train D\n",
        "    ###############################################\n",
        "    for p in D.parameters():  \n",
        "        p.requires_grad = True\n",
        "    for p in CD.parameters():  \n",
        "        p.requires_grad = False\n",
        "    for p in E.parameters():  \n",
        "        p.requires_grad = False\n",
        "    for p in G.parameters():  \n",
        "        p.requires_grad = False\n",
        "\n",
        "    for iters in range(d_iter):\n",
        "        d_optimizer.zero_grad()\n",
        "        real_images = gen_load.__next__()\n",
        "        if real_images.shape[0]==1:\n",
        "          real_images = gen_load.__next__() \n",
        "        _batch_size = real_images.size(0)\n",
        "        z_rand = Variable(torch.randn((_batch_size,latent_dim)),volatile=True).cuda()\n",
        "        real_images = Variable(real_images,volatile=True).cuda()\n",
        "        z_hat = E(real_images).view(_batch_size,-1)\n",
        "        x_hat = G(z_hat)\n",
        "        x_rand = G(z_rand)\n",
        "        x_loss2 = -2*D(real_images).mean()+D(x_hat).mean()+D(x_rand).mean()\n",
        "        gradient_penalty_r = calc_gradient_penalty(D,real_images.data, x_rand.data)\n",
        "        gradient_penalty_h = calc_gradient_penalty(D,real_images.data, x_hat.data)\n",
        "\n",
        "        loss2 = x_loss2+gradient_penalty_r+gradient_penalty_h\n",
        "        loss2.backward(retain_graph=True)\n",
        "        d_optimizer.step()\n",
        "\n",
        "    ###############################################\n",
        "    # Train CD\n",
        "    ###############################################\n",
        "    for p in D.parameters():  \n",
        "        p.requires_grad = False\n",
        "    for p in CD.parameters():  \n",
        "        p.requires_grad = True\n",
        "    for p in E.parameters():  \n",
        "        p.requires_grad = False\n",
        "    for p in G.parameters():  \n",
        "        p.requires_grad = False\n",
        "\n",
        "    for iters in range(cd_iter):\n",
        "        cd_optimizer.zero_grad()\n",
        "        z_rand = Variable(torch.randn((_batch_size,latent_dim)),volatile=True).cuda()\n",
        "        print(_batch_size)\n",
        "        gradient_penalty_cd = calc_gradient_penalty(CD,z_hat.data, z_rand.data)\n",
        "        loss3 = -CD(z_rand).mean() - c_loss + gradient_penalty_cd\n",
        "\n",
        "        loss3.backward(retain_graph=True)\n",
        "        cd_optimizer.step()\n",
        "\n",
        "    ###############################################\n",
        "    # Visualization\n",
        "    ###############################################\n",
        "\n",
        "    if iteration % 10 == 0:\n",
        "        print('[{}/{}]'.format(iteration,TOTAL_ITER),\n",
        "              'D: {:<8.3}'.format(loss2.data[0].cpu().numpy()), \n",
        "              'En_Ge: {:<8.3}'.format(loss1.data[0].cpu().numpy()),\n",
        "              'Code: {:<8.3}'.format(loss3.data[0].cpu().numpy()),\n",
        "              )\n",
        "        feat = np.squeeze((0.5*real_images[0]+0.5).data.cpu().numpy())\n",
        "        feat = nib.Nifti1Image(feat,affine = np.eye(4))\n",
        "        plotting.plot_img(feat,title=\"X_Real\")\n",
        "        plotting.show()\n",
        "\n",
        "        feat = np.squeeze((0.5*x_hat[0]+0.5).data.cpu().numpy())\n",
        "        feat = nib.Nifti1Image(feat,affine = np.eye(4))\n",
        "        plotting.plot_img(feat,title=\"X_DEC\")\n",
        "        plotting.show()\n",
        "\n",
        "        feat = np.squeeze((0.5*x_rand[0]+0.5).data.cpu().numpy())\n",
        "        feat = nib.Nifti1Image(feat,affine = np.eye(4))\n",
        "        plotting.plot_img(feat,title=\"X_rand\")\n",
        "        plotting.show()\n",
        "\n",
        "    ###############################################\n",
        "    # Model Save\n",
        "    ###############################################\n",
        "    if (iteration+1)%500 ==0: \n",
        "        torch.save(G.state_dict(),'./checkpoint/G_iter'+str(iteration+1+es)+'.pth')\n",
        "        torch.save(D.state_dict(),'./checkpoint/D_iter'+str(iteration+1+es)+'.pth')\n",
        "        torch.save(E.state_dict(),'./checkpoint/E_iter'+str(iteration+1+es)+'.pth')\n",
        "        torch.save(CD.state_dict(),'./checkpoint/CD_iter'+str(iteration+1+es)+'.pth')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 1, 64, 64, 64])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1698: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:67: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:68: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:94: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-6afdc624649c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mloss3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mCD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_rand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mc_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgradient_penalty_cd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mloss3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mcd_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [1000, 512, 4, 4, 4]] is at version 5; expected version 4 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUeEq0TeDzyy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r21iMguKErKY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jviNRn6BErH0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nImhagtGErEs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjc8P1M5ErCM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1AgohhiEq_k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcAB97LoEq9H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}